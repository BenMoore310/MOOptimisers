{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from itertools import product\n",
    "from scipy.stats import qmc  # For Latin Hypercube Sampling\n",
    "import torch\n",
    "import gpytorch\n",
    "import random\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import scienceplots\n",
    "from scipy.stats import norm\n",
    "\n",
    "# plt.style.available\n",
    "# plt.style.use(['science', 'notebook'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, meanPrior):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        if meanPrior == 'max':\n",
    "            # self.mean_module = gpytorch.means.ZeroMean()\n",
    "            self.mean_module = gpytorch.means.ConstantMean()\n",
    "            # self.mean_module.constant = torch.nn.Parameter(torch.tensor(torch.max(train_y)))\n",
    "            self.mean_module.constant.data = torch.tensor(torch.max(train_y))\n",
    "\n",
    "        else:\n",
    "            # self.mean_module = gpytorch.means.ConstantMean(constant_prior=torch.max(train_y))\n",
    "            self.mean_module = gpytorch.means.ZeroMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "def GPTrain(features, targets, meanPrior):\n",
    "\n",
    "    tensorSamplesXY = torch.from_numpy(features)\n",
    "    tensorSamplesZ = torch.from_numpy(targets)\n",
    "\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood() \n",
    "    model = ExactGPModel(tensorSamplesXY, tensorSamplesZ, likelihood, meanPrior)\n",
    "    likelihood.noise = 1e-4\n",
    "    likelihood.noise_covar.raw_noise.requires_grad_(False)\n",
    "\n",
    "    training_iter = 250\n",
    "    # Find optimal model hyperparameters\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.05)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(tensorSamplesXY)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, tensorSamplesZ)\n",
    "        loss.backward()\n",
    "        # print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "        #     i + 1, training_iter, loss.item(),\n",
    "        #     model.covar_module.base_kernel.lengthscale.item(), #.kernels[0] after base_kernel if have multiple kernels\n",
    "        #     model.likelihood.noise.item()\n",
    "        # ))\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def GPEval(model, newFeatures):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        observed_pred = model(torch.from_numpy(newFeatures))\n",
    "\n",
    "    mean_pred = observed_pred.mean.numpy()\n",
    "\n",
    "    return mean_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DifferentialEvolution:\n",
    "    def __init__(self, bounds, objective_function, pop_size=50, mutation_factor=0.8, crossover_prob=0.7, max_generations=200, method='random'):\n",
    "        \"\"\"\n",
    "        Initialize the Differential Evolution (DE) optimizer.\n",
    "        \n",
    "        Parameters:\n",
    "        bounds (list of tuple): List of (min, max) bounds for each dimension.\n",
    "        pop_size (int): Number of candidate solutions in the population.\n",
    "        mutation_factor (float): Scaling factor for mutation [0, 2].\n",
    "        crossover_prob (float): Crossover probability [0, 1].\n",
    "        max_generations (int): Maximum number of generations to evolve.\n",
    "        method (str): Population initialization method ('random' or 'lhs').\n",
    "        \"\"\"\n",
    "        self.bounds = np.array(bounds)\n",
    "        self.dimensions = len(bounds)\n",
    "        self.pop_size = pop_size\n",
    "        self.mutation_factor = mutation_factor\n",
    "        self.crossover_prob = crossover_prob\n",
    "        self.max_generations = max_generations\n",
    "        self.method = method\n",
    "        \n",
    "        # Initialize population\n",
    "        self.population = self.initialize_population()\n",
    "        self.best_solution = None\n",
    "        self.best_fitness = np.inf\n",
    "        self.objective_function = objective_function\n",
    "    \n",
    "    def initialize_population(self):\n",
    "        \"\"\"Initialize population using random sampling or Latin Hypercube Sampling.\"\"\"\n",
    "        if self.method == 'lhs':\n",
    "            # Latin Hypercube Sampling\n",
    "            sampler = qmc.LatinHypercube(d=self.dimensions)\n",
    "            sample = sampler.random(n=self.pop_size)\n",
    "            population = qmc.scale(sample, self.bounds[:, 0], self.bounds[:, 1])\n",
    "        else:\n",
    "            # Random Sampling\n",
    "            population = np.random.rand(self.pop_size, self.dimensions)\n",
    "            for i in range(self.dimensions):\n",
    "                population[:, i] = self.bounds[i, 0] + population[:, i] * (self.bounds[i, 1] - self.bounds[i, 0])\n",
    "        \n",
    "        # print(population.shape)\n",
    "        return population\n",
    "    \n",
    "    def mutate(self, target_idx):\n",
    "        \"\"\"Mutation using DE/best/1 strategy.\"\"\"\n",
    "        # Choose three random and distinct individuals different from target_idx\n",
    "        indices = [idx for idx in range(self.pop_size) if idx != target_idx]\n",
    "        np.random.shuffle(indices)\n",
    "        r1, r2 , r3= indices[:3]\n",
    "        \n",
    "        # Best individual in current population\n",
    "\n",
    "        # print(self.population.shape)\n",
    "\n",
    "        #TODO  instead of this list comprehension bollocks just evaluate them all at once\n",
    "        #as thats what i think it wants, then find the minimum of the results. \n",
    "\n",
    "\n",
    "        predictedValues = GPEval(self.objective_function, self.population)\n",
    "\n",
    "        best_idx = np.argsort(predictedValues)[:1]\n",
    "\n",
    "        best = self.population[best_idx]\n",
    "\n",
    "        # best_idx = np.argmin([self.objective_function.predict(ind) for ind in self.population])\n",
    "        # best = self.population[best_idx]\n",
    "        \n",
    "        # Mutant vector: v = best + F * (r1 - r2)\n",
    "        mutant = best + self.mutation_factor * (self.population[r1] - self.population[r2])\n",
    "        \n",
    "        # Ensure mutant vector is within bounds\n",
    "        mutant = np.clip(mutant, self.bounds[:, 0], self.bounds[:, 1])\n",
    "        \n",
    "        return mutant\n",
    "    \n",
    "    def crossover(self, target, mutant):\n",
    "        \"\"\"Crossover to create trial vector.\"\"\"\n",
    "        trial = np.copy(target)\n",
    "        # print(trial.shape)\n",
    "        # print(mutant.shape)\n",
    "        for i in range(self.dimensions):\n",
    "            if np.random.rand() < self.crossover_prob or i == np.random.randint(self.dimensions):\n",
    "                # print(trial[i], mutant[i])\n",
    "                trial[i] = mutant[i]\n",
    "        return trial\n",
    "    \n",
    "    def select(self, target, trial):\n",
    "        \"\"\"Selection: Return the individual with the better fitness.\"\"\"\n",
    "        if self.objective_function.predict(trial) < self.objective_function.predict(target):\n",
    "            return trial\n",
    "        return target\n",
    "\n",
    "    def select(self, target, trial):\n",
    "        \"\"\"Selection: Return the individual with the better fitness.\"\"\"\n",
    "        if GPEval(self.objective_function, trial) < GPEval(self.objective_function, target):\n",
    "            return trial\n",
    "        return target\n",
    "    \n",
    "    def optimize(self):\n",
    "        \"\"\"Run the Differential Evolution optimization.\"\"\"\n",
    "        # x_range = np.linspace(-5, 5, 100)\n",
    "        # y_range = np.linspace(-5, 5, 100)\n",
    "        # X, Y = np.meshgrid(x_range, y_range)\n",
    "        # Z = ackley_function(X, Y)\n",
    "        x_range = np.linspace(self.bounds[0,0], self.bounds[0,1],50)\n",
    "        y_range = np.linspace(self.bounds[1,0], self.bounds[1,1],50)\n",
    "        fullRange = list(product(x_range, y_range))\n",
    "        fullRangeArray = np.array(fullRange)\n",
    "        # y_pred = self.objective_function.predict(fullRangeArray)\n",
    "        y_pred = GPEval(self.objective_function, fullRangeArray)\n",
    "\n",
    "        for generation in range(self.max_generations):\n",
    "            new_population = np.zeros_like(self.population)\n",
    "            allTrials = np.zeros_like(self.population)\n",
    "            allTargets = np.zeros_like(self.population)\n",
    "            # print(self.population.shape)\n",
    "            for i in range(self.pop_size):\n",
    "                target = self.population[i]\n",
    "                # print('break')\n",
    "                # print(i)\n",
    "                mutant = self.mutate(i)\n",
    "                # print(mutant)\n",
    "                mutant = np.reshape(mutant, (2,))\n",
    "                # print(mutant)\n",
    "                trial = self.crossover(target, mutant)\n",
    "                trial = np.reshape(trial, (1,-1))\n",
    "                target = np.reshape(target, (1,-1))\n",
    "                # print('for select', trial.shape, target.shape)\n",
    "                new_population[i] = self.select(target, trial)\n",
    "            \n",
    "            # Update the population\n",
    "            self.population = new_population\n",
    "            \n",
    "            # Track the best solution\n",
    "            # best_idx = np.argmin([self.objective_function.predict(ind) for ind in self.population])\n",
    "            # best_fitness = self.objective_function.predict(self.population[best_idx])\n",
    "            \n",
    "            # predictedValues = self.objective_function.predict(self.population)\n",
    "            predictedValues = GPEval(self.objective_function, self.population)\n",
    "\n",
    "            best_idx = np.argsort(predictedValues)[:1]\n",
    "\n",
    "            # best_fitness = self.objective_function.predict(self.population[best_idx])\n",
    "            best_fitness = GPEval(self.objective_function, self.population[best_idx])\n",
    "\n",
    "            if best_fitness < self.best_fitness:\n",
    "                self.best_fitness = best_fitness\n",
    "                self.best_solution = self.population[best_idx]\n",
    "            \n",
    "            # plt.contourf(x_range, y_range, y_pred, levels=50, cmap='viridis')\n",
    "        plt.scatter(fullRangeArray[:,0], fullRangeArray[:,1], c = y_pred)\n",
    "\n",
    "        plt.scatter(self.population[:, 0], self.population[:, 1], color='red', label='Final Population', s=5)\n",
    "        # plt.scatter(best_solution[0], best_solution[1], color='blue', label='Best Solution', s=100)\n",
    "        # plt.legend()\n",
    "        plt.title(\"Local Surrogate\")\n",
    "        plt.colorbar()\n",
    "        plt.clim(0,14)\n",
    "        plt.xlim(self.bounds[0,0], self.bounds[0,1])\n",
    "        plt.ylim(self.bounds[1,0], self.bounds[1,1])\n",
    "        # plt.savefig('localGP.png')\n",
    "        plt.show()\n",
    "        # # Debug information\n",
    "        print(f\"Generation {generation + 1}: Best RBF Fitness = {self.best_fitness}\")\n",
    "        \n",
    "        return self.best_solution, self.best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ackley_function(x, y, a=20, b=0.2, c=2 * np.pi):\n",
    "    term1 = -a * np.exp(-b * np.sqrt(0.5 * (x**2 + y**2)))\n",
    "    term2 = -np.exp(0.5 * (np.cos(c * x) + np.cos(c * y)))\n",
    "    return term1 + term2 + a + np.exp(1)\n",
    "\n",
    "def objective_function(vec):\n",
    "    \"\"\"Objective function wrapper for optimization.\n",
    "    Args:\n",
    "        vec (np.ndarray): A vector representing candidate solution (x, y).\n",
    "    Returns:\n",
    "        float: Fitness value of the solution.\n",
    "    \"\"\"\n",
    "    x, y = vec\n",
    "    return ackley_function(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TS_DDEO:\n",
    "    def __init__(self, bounds, pop_size, c1=2.05, c2=2.05, PSOFE=50, BDDOFE=15, mutation_factor=0.8, crossover_prob=0.7):\n",
    "        self.globalBounds = np.array(bounds)\n",
    "        self.dimensions = len(bounds)\n",
    "        self.pop_size = pop_size\n",
    "        self.max_generations = PSOFE\n",
    "        self.feFeatures = np.empty((0, self.dimensions))  # Consistent with dimensions\n",
    "        self.globalBestFeature = None\n",
    "        self.feTargets = np.empty(0) \n",
    "        self.globalBestTarget = np.inf  # Initialize as infinity\n",
    "        self.popBestFeature = np.empty((self.pop_size, self.dimensions))\n",
    "        self.popBestTargets = np.full(self.pop_size, np.inf)  # Initialize with inf\n",
    "        self.generator = np.random.default_rng()\n",
    "        self.BBDOIter = BDDOFE\n",
    "        # Initialize population and velocities\n",
    "        self.population = self.initialisePopulation()\n",
    "        self.velocities = self.initialiseVelocities()\n",
    "\n",
    "        # PSO coefficients\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.phi = c1 + c2\n",
    "        self.chi = 2 / abs((2 - self.phi - np.sqrt(self.phi**2 - 4 * self.phi)))\n",
    "\n",
    "        self.mutation_factor = mutation_factor\n",
    "        self.crossover_prob = crossover_prob\n",
    "\n",
    "    def initialisePopulation(self):\n",
    "        \"\"\"Initializes the population using Latin Hypercube Sampling.\"\"\"\n",
    "        sampler = qmc.LatinHypercube(d=self.dimensions)\n",
    "        sample = sampler.random(n=self.pop_size)\n",
    "        population = qmc.scale(sample, self.globalBounds[:, 0], self.globalBounds[:, 1])\n",
    "\n",
    "        for particle in population:\n",
    "            # Evaluate the objective function\n",
    "            target = objective_function(particle)\n",
    "            self.feTargets = np.append(self.feTargets, target)\n",
    "            self.feFeatures = np.vstack((self.feFeatures, particle))\n",
    "\n",
    "        # Initialize the personal bests\n",
    "        self.popBestFeature = self.feFeatures.copy()\n",
    "        self.popBestTargets = self.feTargets.copy()\n",
    "\n",
    "        # Initialize the global best\n",
    "        bestIdx = np.argmin(self.feTargets)\n",
    "        self.globalBestFeature = self.feFeatures[bestIdx]\n",
    "        self.globalBestTarget = self.feTargets[bestIdx]\n",
    "\n",
    "        # Plot initial population\n",
    "        plt.scatter(self.feFeatures[:, 0], self.feFeatures[:, 1], c=self.feTargets, cmap='viridis')\n",
    "        plt.title('Initial Population')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "        return population\n",
    "\n",
    "    def initialiseVelocities(self):\n",
    "        \"\"\"Initializes particle velocities as a small fraction of the bounds range.\"\"\"\n",
    "        velocity_range = (self.globalBounds[:, 1] - self.globalBounds[:, 0]) * 0.001\n",
    "        return self.generator.uniform(low=-velocity_range, high=velocity_range, size=(self.pop_size, self.dimensions))\n",
    "\n",
    "    def updateVelocity(self):\n",
    "        \"\"\"Updates the velocities of the particles.\"\"\"\n",
    "        r1 = self.generator.random(size=(self.pop_size, self.dimensions))\n",
    "        r2 = self.generator.random(size=(self.pop_size, self.dimensions))\n",
    "        cognitive = self.c1 * r1 * (self.popBestFeature - self.population)\n",
    "        social = self.c2 * r2 * (self.globalBestFeature - self.population)\n",
    "        self.velocities = self.chi * (self.velocities + cognitive + social)\n",
    "\n",
    "        # print(self.velocities)\n",
    "\n",
    "    def updatePosition(self):\n",
    "        \"\"\"Updates the positions of the particles.\"\"\"\n",
    "        self.population += self.velocities\n",
    "        # print(self.population)\n",
    "\n",
    "    def clipPositions(self):\n",
    "        \"\"\"Clips particle positions to stay within bounds.\"\"\"\n",
    "        self.population = np.clip(self.population, self.globalBounds[:, 0], self.globalBounds[:, 1])\n",
    "\n",
    "    def stage1(self):\n",
    "        \"\"\"Runs the PSO optimization loop.\"\"\"\n",
    "        x_range = np.linspace(self.globalBounds[0, 0], self.globalBounds[0, 1], 100)\n",
    "        y_range = np.linspace(self.globalBounds[1, 0], self.globalBounds[1, 1], 100)\n",
    "        X, Y = np.meshgrid(x_range, y_range)\n",
    "        Z = ackley_function(X, Y)\n",
    "\n",
    "        iteration = 1\n",
    "\n",
    "        while len(self.feFeatures) < (self.pop_size + self.max_generations):\n",
    "            # Train surrogate model and find a solution\n",
    "            GPModel = GPTrain(self.feFeatures, self.feTargets, meanPrior='zero')\n",
    "            globalDE = DifferentialEvolution(self.globalBounds, GPModel)\n",
    "            bestGPSolution, bestGPFitness = globalDE.optimize()\n",
    "\n",
    "            # Evaluate the found solution\n",
    "            bestGPSolution = np.reshape(bestGPSolution, (1, self.dimensions))\n",
    "            target = objective_function(bestGPSolution[0])\n",
    "            self.feTargets = np.append(self.feTargets, target)\n",
    "            self.feFeatures = np.vstack((self.feFeatures, bestGPSolution))\n",
    "\n",
    "            # Update global best if necessary\n",
    "            if target < self.globalBestTarget:\n",
    "                self.globalBestFeature = bestGPSolution[0]\n",
    "                self.globalBestTarget = target\n",
    "\n",
    "            # Update velocities and positions\n",
    "            self.updateVelocity()\n",
    "            self.updatePosition()\n",
    "            self.clipPositions()\n",
    "\n",
    "            # Evaluate swarm on surrogate model\n",
    "            swarmOnGP = GPEval(GPModel, self.population)\n",
    "            betterThanPBest = swarmOnGP < self.popBestTargets\n",
    "\n",
    "            # Evaluate selected particles\n",
    "            toEvaluate = np.where(betterThanPBest)[0]\n",
    "            for idx in toEvaluate:\n",
    "                particle = self.population[idx]\n",
    "                target = objective_function(particle)\n",
    "\n",
    "                # Update feature and target logs\n",
    "                self.feTargets = np.append(self.feTargets, target)\n",
    "                self.feFeatures = np.vstack((self.feFeatures, particle))\n",
    "\n",
    "                # Update personal best if necessary\n",
    "                if target < self.popBestTargets[idx]:\n",
    "                    self.popBestTargets[idx] = target\n",
    "                    self.popBestFeature[idx] = particle\n",
    "\n",
    "\n",
    "            #refind best values\n",
    "            bestIdx = np.argmin(self.feTargets)\n",
    "            self.globalBestFeature = self.feFeatures[bestIdx]\n",
    "            self.globalBestTarget = self.feTargets[bestIdx]\n",
    "            iteration += 1\n",
    "            # Plot the optimization progress\n",
    "            plt.contourf(X, Y, Z, levels=50, cmap='viridis')\n",
    "            plt.scatter(self.population[:, 0], self.population[:, 1], color='red', label='Swarm', s=10)\n",
    "            plt.legend()\n",
    "            plt.title(f\"PSO Optimization - Iteration {iteration + 1}\")\n",
    "            plt.colorbar()\n",
    "            plt.clim(0, 14)\n",
    "            plt.show()\n",
    "\n",
    "            plt.scatter(self.feFeatures[:, 0], self.feFeatures[:, 1], c=self.feTargets, cmap='viridis')\n",
    "            plt.title('Initial Population')\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "\n",
    "            # Debug information\n",
    "            print(f\"Iteration {iteration}: Best Fitness = {self.globalBestTarget}\")\n",
    "    \n",
    "    def mutate(self, target_idx, currentGP):\n",
    "        \"\"\"Mutation using DE/best/1 strategy.\"\"\"\n",
    "        # Choose three random and distinct individuals different from target_idx\n",
    "        indices = [idx for idx in range(self.pop_size) if idx != target_idx]\n",
    "        np.random.shuffle(indices)\n",
    "        r1, r2 , r3= indices[:3]\n",
    "\n",
    "        predictedValues = GPEval(currentGP, self.population)\n",
    "\n",
    "        best_idx = np.argsort(predictedValues)[:1]\n",
    "\n",
    "        best = self.population[best_idx]\n",
    "\n",
    "        # Mutant vector: v = best + F * (r1 - r2)\n",
    "        mutant = best + self.mutation_factor * (self.population[r1] - self.population[r2])\n",
    "        \n",
    "        # Ensure mutant vector is within bounds\n",
    "        mutant = np.clip(mutant, self.globalBounds[:, 0], self.globalBounds[:, 1])\n",
    "        \n",
    "        return mutant\n",
    "    \n",
    "    def crossover(self, target, mutant):\n",
    "        \"\"\"Crossover to create trial vector.\"\"\"\n",
    "        trial = np.copy(target)\n",
    "        # print(trial.shape)\n",
    "        # print(mutant.shape)\n",
    "        for i in range(self.dimensions):\n",
    "            if np.random.rand() < self.crossover_prob or i == np.random.randint(self.dimensions):\n",
    "                # print(trial[i], mutant[i])\n",
    "                trial[i] = mutant[i]\n",
    "        return trial\n",
    "\n",
    "    def localRBF(self, numSolutions):\n",
    "\n",
    "        bestFeatures = np.empty((numSolutions,2))\n",
    "        bestTargets = np.empty(numSolutions)\n",
    "\n",
    "        #find c best solutions\n",
    "        bestIndices = np.argsort(self.feTargets)[:numSolutions]\n",
    "\n",
    "        for i in range(numSolutions):\n",
    "            bestFeatures[i] = self.feFeatures[bestIndices[i]]\n",
    "            bestTargets[i] = self.feTargets[bestIndices[i]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        x_min, x_max = np.min(bestFeatures[:, 0]), np.max(bestFeatures[:, 0])\n",
    "        y_min, y_max = np.min(bestFeatures[:, 1]), np.max(bestFeatures[:, 1])\n",
    "\n",
    "        bounds = [(x_min, x_max), (y_min, y_max)]\n",
    "\n",
    "        # pairwiseDistancesLocal = np.linalg.norm(bestFeatures[:, np.newaxis] - bestFeatures, axis=2)\n",
    "        # avgDistanceLocal = np.mean(pairwiseDistancesLocal)\n",
    "\n",
    "        localGP = GPTrain(bestFeatures, bestTargets, meanPrior='max')\n",
    "\n",
    "        # localRBF = RBFSurrogateModel(epsilon=1.0)\n",
    "        # localRBF.fit(bestFeatures, bestTargets)\n",
    "\n",
    "        # functionEval = localRBF.predict()\n",
    "        localDE = DifferentialEvolution(bounds, localGP )\n",
    "        bestLocalSolution, bestLocalFitness = localDE.optimize()\n",
    "\n",
    "        return bestLocalSolution\n",
    "    \n",
    "    def fullCrossover(self):\n",
    "\n",
    "        #build surrogate using all points in population\n",
    "        crossoverGP = GPTrain(self.feFeatures, self.feTargets, meanPrior='max')\n",
    "\n",
    "        best_idx = np.argmin(self.feTargets)\n",
    "        bestFeature = self.feFeatures[best_idx]\n",
    "        bestTarget = self.feTargets[best_idx]\n",
    "\n",
    "        RVS = random.sample(range(0, self.dimensions), self.dimensions)\n",
    "\n",
    "        print(self.feFeatures.shape)\n",
    "        print(bestFeature)\n",
    "\n",
    "        x_range = np.linspace(self.globalBounds[0,0], self.globalBounds[0,1],100)\n",
    "        y_range = np.linspace(self.globalBounds[1,0], self.globalBounds[1,1],100)\n",
    "        fullRange = list(product(x_range, y_range))\n",
    "        fullRangeArray = np.array(fullRange)\n",
    "        # y_pred = self.objective_function.predict(fullRangeArray)\n",
    "        y_pred = GPEval(crossoverGP, fullRangeArray)\n",
    "\n",
    "        tempPop = np.full_like((self.feFeatures), bestFeature)\n",
    "\n",
    "        # print(tempPop)\n",
    "\n",
    "        for i in RVS:\n",
    "            # print(i)\n",
    "\n",
    "            tempPop[:,i] = self.feFeatures[:,i]\n",
    "\n",
    "            tempPopEval = GPEval(crossoverGP, tempPop)\n",
    "\n",
    "            plt.scatter(fullRangeArray[:,0], fullRangeArray[:,1], c = y_pred, alpha = 0.5)\n",
    "            plt.scatter(tempPop[:, 0], tempPop[:, 1], color='red', label='crossover', s=10, marker='x')\n",
    "            plt.scatter(bestFeature[0], bestFeature[1], color='blue', label='Best Solution', s=10)\n",
    "            plt.legend()\n",
    "            plt.title(\"Full-Crossover\")\n",
    "            plt.colorbar()\n",
    "            plt.clim(0, 14)\n",
    "            # plt.savefig(f'DEPlots/{generation}.png')\n",
    "            plt.show()\n",
    "\n",
    "            tempPopBestIdx = np.argmin(tempPopEval)\n",
    "            if tempPopEval[tempPopBestIdx] > bestTarget:\n",
    "                tempPop = np.full_like((self.feFeatures), tempPop[tempPopBestIdx])\n",
    "                print('new best value!')\n",
    "\n",
    "            \n",
    "\n",
    "        #take final best predicted value and explicitely evaluate\n",
    "        self.feTargets = np.append(self.feTargets, objective_function(tempPop[tempPopBestIdx]))\n",
    "        self.feFeatures = np.vstack((self.feFeatures, tempPop[tempPopBestIdx]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def stage2(self):\n",
    "\n",
    "        iteration = 0\n",
    "        \n",
    "        while iteration < self.BBDOIter:\n",
    "            #DE screening stage\n",
    "            GPModel = GPTrain(self.feFeatures, self.feTargets, meanPrior='max')\n",
    "\n",
    "            new_population = np.zeros_like(self.population)\n",
    "                \n",
    "            for i in range(self.pop_size):\n",
    "                # print(i)\n",
    "                target = self.population[i]\n",
    "                mutant = self.mutate(i, GPModel)\n",
    "                mutant = np.reshape(mutant, (2,))\n",
    "\n",
    "                trial = self.crossover(target, mutant)\n",
    "                trial = np.reshape(trial, (1,-1))\n",
    "                target = np.reshape(target, (1,-1))\n",
    "                new_population[i] = trial\n",
    "                \n",
    "                # Update the population\n",
    "            self.population = new_population\n",
    "\n",
    "            popOnGP = GPEval(GPModel, self.population)\n",
    "\n",
    "            #evaluating whole landscape on RBF for plotting reasons:\n",
    "            x_range = np.linspace(-5,5,50)\n",
    "            y_range = np.linspace(-5,5,50)\n",
    "            fullRange = list(product(x_range, y_range))\n",
    "            fullRangeArray = np.array(fullRange)\n",
    "            y_pred = GPEval(GPModel, fullRangeArray)\n",
    "\n",
    "            #function evaluation of best predicted child\n",
    "            best_idx = np.argmin(popOnGP)\n",
    "\n",
    "            bestFeature = self.population[best_idx]\n",
    "\n",
    "            # print('best index =', best_idx)\n",
    "            #evaluate best child and add results to global stores of FE features and targets\n",
    "            self.feTargets = np.append(self.feTargets, objective_function(self.population[best_idx]))\n",
    "            self.feFeatures = np.vstack((self.feFeatures, self.population[best_idx]))\n",
    "\n",
    "            plt.scatter(fullRangeArray[:,0], fullRangeArray[:,1], c = y_pred)\n",
    "\n",
    "            plt.scatter(self.population[:, 0], self.population[:, 1], color='red', label='Final Population', s=5)\n",
    "            plt.scatter(bestFeature[0], bestFeature[1], color='blue', label='Best Solution', s=10)\n",
    "            # plt.legend()\n",
    "            plt.title(\"Global Surrogate\")\n",
    "            plt.colorbar()\n",
    "            plt.clim(0,14)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            #construct local RBF using c best solutions, find minima using DE, and evaluate at that minima\n",
    "\n",
    "\n",
    "            bestLocalSolution = self.localRBF(15)\n",
    "\n",
    "            bestLocalSolution = np.reshape(bestLocalSolution, (2,))\n",
    "\n",
    "            print('best local Solution', bestLocalSolution)\n",
    "\n",
    "            self.feTargets = np.append(self.feTargets, objective_function(bestLocalSolution))\n",
    "            self.feFeatures = np.vstack((self.feFeatures, bestLocalSolution)) \n",
    "\n",
    "            self.fullCrossover()\n",
    "\n",
    "            iteration += 1\n",
    "            bestIdx = np.argmin(self.feTargets)\n",
    "\n",
    "            print(f\"Iteration {iteration}: Best Fitness = {self.feTargets[bestIdx]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lipschitz_global_underestimate(f_values, samplesXY, L, test_points):\n",
    "    \"\"\"\n",
    "    Compute the Lipschitz-based global underestimate at specific points.\n",
    "\n",
    "    Parameters:\n",
    "    f_values: np.ndarray of shape (n_samples,)\n",
    "        The function values at the sampled points.\n",
    "    samplesXY: np.ndarray of shape (n_samples, 2)\n",
    "        Array of the sampled (x, y) points.\n",
    "    L: float\n",
    "        The Lipschitz constant.\n",
    "    test_points: np.ndarray of shape (n, 2)\n",
    "        Array of (x, y) points at which to compute the underestimate.\n",
    "\n",
    "    Returns:\n",
    "    Z_under: np.ndarray of shape (n,)\n",
    "        The global Lipschitz-based underestimate values at the test points.\n",
    "    \"\"\"\n",
    "    n_test_points = test_points.shape[0]\n",
    "    Z_under = np.full(n_test_points, -np.inf)  # Initialize with very low values\n",
    "\n",
    "    # Loop over all sample points to compute their individual underestimates\n",
    "    for i, (x_i, y_i) in enumerate(samplesXY):\n",
    "        f_x_i_y_i = f_values[i]\n",
    "        \n",
    "        # Compute the distance from each test point to the sample point (x_i, y_i)\n",
    "        distances = np.sqrt((test_points[:, 0] - x_i)**2 + (test_points[:, 1] - y_i)**2)\n",
    "        \n",
    "        # Compute the local Lipschitz underestimate for this sample\n",
    "        Z_local_under = f_x_i_y_i - L * distances\n",
    "        \n",
    "        # Update the global underestimate by taking the maximum across samples\n",
    "        Z_under = np.maximum(Z_under, Z_local_under)\n",
    "    \n",
    "    return Z_under\n",
    "\n",
    "def estimate_lipschitz_constant(samplesXY, f_values):\n",
    "\n",
    "    \"\"\"\n",
    "    Estimate the Lipschitz constant based on known sample points and their function values.\n",
    "    \n",
    "    Parameters:\n",
    "    samplesXY: np.ndarray of shape (n_samples, 2)\n",
    "        Array of the sampled (x, y) points.\n",
    "    f_values: np.ndarray of shape (n_samples,)\n",
    "        Array of function values at the sampled points.\n",
    "    \n",
    "    Returns:\n",
    "    L_est: float\n",
    "        The estimated Lipschitz constant.\n",
    "    \"\"\"\n",
    "    n_samples = samplesXY.shape[0]\n",
    "    # print(samplesXY.shape)\n",
    "    # print(n_samples)\n",
    "    L_est = 0.0\n",
    "    \n",
    "    # Loop over all pairs of points to estimate L\n",
    "    for i in range(n_samples):\n",
    "        for j in range(i + 1, n_samples):\n",
    "            # Compute the Euclidean distance between points i and j\n",
    "            dist = np.linalg.norm(samplesXY[i] - samplesXY[j])\n",
    "            if dist > 0:\n",
    "                # Compute the absolute difference in function values\n",
    "                f_diff = np.abs(f_values[i] - f_values[j])\n",
    "                # Compute the slope and update the maximum\n",
    "                # print(L_est, f_diff/dist)\n",
    "                L_est = max(L_est, f_diff / dist)\n",
    "    \n",
    "    return L_est\n",
    "\n",
    "class LSADE:\n",
    "    def __init__(self, bounds, pop_size=50, mutation_factor=0.8, crossover_prob=0.7, method='random'):\n",
    "        \"\"\"\n",
    "        Initialize the Differential Evolution (DE) optimizer.\n",
    "        \n",
    "        Parameters:\n",
    "        bounds (list of tuple): List of (min, max) bounds for each dimension.\n",
    "        pop_size (int): Number of candidate solutions in the population.\n",
    "        mutation_factor (float): Scaling factor for mutation [0, 2].\n",
    "        crossover_prob (float): Crossover probability [0, 1].\n",
    "        max_generations (int): Maximum number of generations to evolve.\n",
    "        method (str): Population initialization method ('random' or 'lhs').\n",
    "        \"\"\"\n",
    "        self.bounds = np.array(bounds)\n",
    "        self.dimensions = len(bounds)\n",
    "        self.pop_size = pop_size\n",
    "        self.mutation_factor = mutation_factor\n",
    "        self.crossover_prob = crossover_prob\n",
    "        # self.max_generations = max_generations\n",
    "        self.method = method\n",
    "        self.feFeatures = np.empty((0,2))\n",
    "        self.feTargets = np.empty(0)        \n",
    "        # Initialize population\n",
    "        self.population = self.initialize_population()\n",
    "\n",
    "        self.best_solution = None\n",
    "        self.best_fitness = np.inf\n",
    "    \n",
    "    def initialize_population(self):\n",
    "        \"\"\"Initialize population using random sampling or Latin Hypercube Sampling.\"\"\"\n",
    "\n",
    "        # print('initial shape', self.feFeatures.shape)\n",
    "        if self.method == 'lhs':\n",
    "            # Latin Hypercube Sampling\n",
    "            sampler = qmc.LatinHypercube(d=self.dimensions)\n",
    "            sample = sampler.random(n=self.pop_size)\n",
    "            population = qmc.scale(sample, self.bounds[:, 0], self.bounds[:, 1])\n",
    "        else:\n",
    "            # Random Sampling\n",
    "            population = np.random.rand(self.pop_size, self.dimensions)\n",
    "            for i in range(self.dimensions):\n",
    "                population[:, i] = self.bounds[i, 0] + population[:, i] * (self.bounds[i, 1] - self.bounds[i, 0])\n",
    "\n",
    "        for i in range(0, len(population)):\n",
    "            self.feTargets = np.append(self.feTargets, objective_function(population[i]))\n",
    "            self.feFeatures = np.vstack((self.feFeatures, population[i]))\n",
    "        \n",
    "        # print('final shape', self.feFeatures.shape)\n",
    "\n",
    "        return population\n",
    "    \n",
    "    def mutate(self, target_idx):\n",
    "        \"\"\"Mutation using DE/best/1 strategy.\"\"\"\n",
    "        # Choose three random and distinct individuals different from target_idx\n",
    "        indices = [idx for idx in range(self.pop_size) if idx != target_idx]\n",
    "        np.random.shuffle(indices)\n",
    "        r1, r2 , r3= indices[:3]\n",
    "        \n",
    "        # Best individual in current population\n",
    "        best_idx = np.argmin([objective_function(ind) for ind in self.population])\n",
    "        best = self.population[best_idx]\n",
    "        \n",
    "        # Mutant vector: v = best + F * (r1 - r2)\n",
    "        mutant = best + self.mutation_factor * (self.population[r1] - self.population[r2])\n",
    "        \n",
    "        # Ensure mutant vector is within bounds\n",
    "        mutant = np.clip(mutant, self.bounds[:, 0], self.bounds[:, 1])\n",
    "        \n",
    "        return mutant\n",
    "    \n",
    "    def crossover(self, target, mutant):\n",
    "        \"\"\"Crossover to create trial vector.\n",
    "        This loops through the features in the vector (dimensions) and sees if any of them crossover. \n",
    "        allows the retention of some original vector features but not others. \n",
    "        \"\"\"\n",
    "\n",
    "        trial = np.copy(target)\n",
    "        # print(trial.shape)\n",
    "        # print(mutant.shape)\n",
    "        for i in range(self.dimensions):\n",
    "            if np.random.rand() < self.crossover_prob or i == np.random.randint(self.dimensions):\n",
    "                # print(trial[i], mutant[i])\n",
    "\n",
    "                trial[i] = mutant[i]\n",
    "        return trial\n",
    "            \n",
    "\n",
    "    # def select(self, target, trial):\n",
    "    #     \"\"\"Selection: Return the individual with the better fitness.\"\"\"\n",
    "    #     if objective_function(trial) < objective_function(target):\n",
    "    #         return trial\n",
    "    #     return target\n",
    "    \n",
    "    def localRBF(self, numSolutions):\n",
    "\n",
    "        bestFeatures = np.empty((numSolutions,2))\n",
    "        bestTargets = np.empty(numSolutions)\n",
    "\n",
    "        #find c best solutions\n",
    "        bestIndices = np.argsort(self.feTargets)[:numSolutions]\n",
    "\n",
    "        for i in range(numSolutions):\n",
    "            bestFeatures[i] = self.feFeatures[bestIndices[i]]\n",
    "            bestTargets[i] = self.feTargets[bestIndices[i]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        x_min, x_max = np.min(bestFeatures[:, 0]), np.max(bestFeatures[:, 0])\n",
    "        y_min, y_max = np.min(bestFeatures[:, 1]), np.max(bestFeatures[:, 1])\n",
    "\n",
    "        bounds = [(x_min, x_max), (y_min, y_max)]\n",
    "\n",
    "        # pairwiseDistancesLocal = np.linalg.norm(bestFeatures[:, np.newaxis] - bestFeatures, axis=2)\n",
    "        # avgDistanceLocal = np.mean(pairwiseDistancesLocal)\n",
    "\n",
    "        localGP = GPTrain(bestFeatures, bestTargets, meanPrior='max')\n",
    "\n",
    "        # localRBF = RBFSurrogateModel(epsilon=1.0)\n",
    "        # localRBF.fit(bestFeatures, bestTargets)\n",
    "\n",
    "        # functionEval = localRBF.predict()\n",
    "        localDE = DifferentialEvolution(bounds, localGP )\n",
    "        bestLocalSolution, bestLocalFitness = localDE.optimize()\n",
    "\n",
    "        return bestLocalSolution\n",
    "    \n",
    "    def optimizerStep(self):\n",
    "        \"\"\"Run the Differential Evolution optimization.\"\"\"\n",
    "        # x_range = np.linspace(-5, 5, 100)\n",
    "        # y_range = np.linspace(-5, 5, 100)\n",
    "        # X, Y = np.meshgrid(x_range, y_range)\n",
    "        # Z = ackley_function(X, Y)\n",
    "\n",
    "        # for generation in range(self.max_generations):\n",
    "        new_population = np.zeros_like(self.population)\n",
    "            \n",
    "        for i in range(self.pop_size):\n",
    "            # print(i)\n",
    "            target = self.population[i]\n",
    "            mutant = self.mutate(i)\n",
    "            trial = self.crossover(target, mutant)\n",
    "            #do not evaluate target/trial vectors, instead just save the trial vectors as the new population\n",
    "            #so they can be evaluated on the global RBF and Lipschitz surrogates later\n",
    "            # new_population[i] = self.select(target, trial)\n",
    "            new_population[i] = trial\n",
    "            \n",
    "            # Update the population\n",
    "        self.population = new_population\n",
    "        # print(new_population.shape)\n",
    "        # pairwise_distances = np.linalg.norm(self.feFeatures[:,np.newaxis] - self.feFeatures, axis=2)\n",
    "        # avg_distance = np.mean(pairwise_distances)\n",
    "        # globalRBF = RBFSurrogateModel(epsilon=1.0)\n",
    "\n",
    "        # globalRBF.fit(self.feFeatures, self.feTargets)\n",
    "\n",
    "        GPModel = GPTrain(self.feFeatures, self.feTargets, meanPrior='zero')\n",
    "\n",
    "        popOnGP = GPEval(GPModel, self.population)\n",
    "\n",
    "        \n",
    "        #evaluating whole landscape on RBF for plotting reasons:\n",
    "        x_range = np.linspace(-5,5,50)\n",
    "        y_range = np.linspace(-5,5,50)\n",
    "        fullRange = list(product(x_range, y_range))\n",
    "        fullRangeArray = np.array(fullRange)\n",
    "        y_pred = GPEval(GPModel, fullRangeArray)\n",
    "\n",
    "\n",
    "        #evaluate current population (children) on RBF\n",
    "        # popOnRBF = globalRBF.predict(self.population)\n",
    "\n",
    "        #function evaluation of best predicted child\n",
    "        best_idx = np.argmin(popOnGP)\n",
    "\n",
    "        bestFeature = self.population[best_idx]\n",
    "\n",
    "        # print('best index =', best_idx)\n",
    "        #evaluate best child and add results to global stores of FE features and targets\n",
    "        self.feTargets = np.append(self.feTargets, objective_function(self.population[best_idx]))\n",
    "        self.feFeatures = np.vstack((self.feFeatures, self.population[best_idx]))\n",
    "\n",
    "        plt.scatter(fullRangeArray[:,0], fullRangeArray[:,1], c = y_pred)\n",
    "\n",
    "        plt.scatter(self.population[:, 0], self.population[:, 1], color='red', label='Final Population', s=5)\n",
    "        plt.scatter(bestFeature[0], bestFeature[1], color='blue', label='Best Solution', s=10)\n",
    "        # plt.legend()\n",
    "        plt.title(\"Global Surrogate\")\n",
    "        plt.colorbar()\n",
    "        plt.clim(0,14)\n",
    "        plt.savefig('globalGP.png')\n",
    "        plt.close()\n",
    "        #generate Lipschitz surrogate, evaluate children, FE evaluate best potential child and add to bank\n",
    "\n",
    "        # print(self.feTargets, self.feFeatures)\n",
    "        # print('final shape', self.feFeatures.shape)\n",
    "\n",
    "        L_est = estimate_lipschitz_constant(self.feFeatures, self.feTargets)\n",
    "\n",
    "        popOnLipschitz = lipschitz_global_underestimate(self.feTargets, self.feFeatures, L_est, self.population)\n",
    "        best_idx = np.argmin(popOnLipschitz)\n",
    "        bestFeature = self.population[best_idx]\n",
    "\n",
    "        self.feTargets = np.append(self.feTargets, objective_function(self.population[best_idx]))\n",
    "        self.feFeatures = np.vstack((self.feFeatures, self.population[best_idx]))        \n",
    "\n",
    "        #evaluating all points in function on Lipschitz for plotting purposes\n",
    "        Z_under = lipschitz_global_underestimate(self.feTargets, self.feFeatures, L_est, fullRangeArray)\n",
    "\n",
    "        plt.scatter(fullRangeArray[:,0], fullRangeArray[:,1], c = Z_under)\n",
    "\n",
    "        plt.scatter(self.population[:, 0], self.population[:, 1], color='red', label='Final Population', s=5)\n",
    "        plt.scatter(bestFeature[0], bestFeature[1], color='blue', label='Best Solution', s=10)\n",
    "        # plt.legend()\n",
    "        plt.title(\"Lipschitz Underestimation\")\n",
    "        plt.colorbar()\n",
    "        plt.clim(0,14)\n",
    "        plt.savefig('lipschitz.png')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "        #construct local RBF using c best solutions, find minima using DE, and evaluate at that minima\n",
    "\n",
    "        bestLocalSolution = self.localRBF(15)\n",
    "\n",
    "        bestLocalSolution = np.reshape(bestLocalSolution, (2,))\n",
    "\n",
    "        print('best local Solution', bestLocalSolution)\n",
    "\n",
    "        self.feTargets = np.append(self.feTargets, objective_function(bestLocalSolution))\n",
    "        self.feFeatures = np.vstack((self.feFeatures, bestLocalSolution)) \n",
    "\n",
    "        plt.scatter(self.feFeatures[:,0], self.feFeatures[:,1], c = self.feTargets)\n",
    "        plt.title('Evaluated Population')\n",
    "        plt.colorbar()\n",
    "        plt.clim(0,14)\n",
    "        plt.savefig('population.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Track the best solution\n",
    "        # best_idx = np.argmin([objective_function(ind) for ind in self.population])\n",
    "        # best_fitness = objective_function(self.population[best_idx])\n",
    "        \n",
    "        # if best_fitness < self.best_fitness:\n",
    "        #     self.best_fitness = best_fitness\n",
    "        #     self.best_solution = self.population[best_idx]\n",
    "            \n",
    "            # plt.contourf(X, Y, Z, levels=50, cmap='viridis')\n",
    "            # plt.scatter(de.population[:, 0], de.population[:, 1], color='red', label='Final Population', s=5)\n",
    "            # # plt.scatter(best_solution[0], best_solution[1], color='blue', label='Best Solution', s=100)\n",
    "            # plt.legend()\n",
    "            # plt.title(\"Ackley Function with Final Population and Best Solution\")\n",
    "            # plt.colorbar()\n",
    "            # plt.show()\n",
    "            # Debug information\n",
    "            # print(f\"Generation {generation + 1}: Best Fitness = {self.best_fitness}\")\n",
    "        print('Best found solution = ', min(self.feTargets))\n",
    "\n",
    "\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "\n",
    "        localGP = Image.open('localGP.png')\n",
    "        globalGP = Image.open('globalGP.png')\n",
    "        lipschitz = Image.open('lipschitz.png')\n",
    "        population = Image.open('population.png')\n",
    "\n",
    "        width, height = localGP.size\n",
    "        combinedImage = Image.new('RGB', (2 * width, 2 * height))\n",
    "        combinedImage.paste(localGP, (0, 0))\n",
    "        combinedImage.paste(lipschitz, (width, 0))\n",
    "        combinedImage.paste(globalGP, (0, height))\n",
    "        combinedImage.paste(population, (width, height))\n",
    "\n",
    "        combinedImage.save(f'plots/{timestamp}.png')\n",
    "\n",
    "\n",
    "        return self.best_solution, self.best_fitness\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESA:\n",
    "    def __init__(self, bounds, pop_size, localPopSize, alpha, gamma, maxFE, mutation_factor=0.8, crossover_prob=0.7):\n",
    "\n",
    "        self.globalBounds = np.array(bounds)\n",
    "        self.dimensions = len(bounds)\n",
    "        self.pop_size = pop_size\n",
    "        self.feFeatures = np.empty((0,2))\n",
    "        self.feTargets = np.empty(0) \n",
    "        # self.k = k\n",
    "        self.population = self.initialiseDatabase()\n",
    "        self.localPopSize = localPopSize\n",
    "\n",
    "        #initialise 4actions x 8states array, all entries initialised to 0.25\n",
    "        self.qTable = np.full((8,4), 0.1)\n",
    "        self.x_best = 0\n",
    "        self.x_bestSolution = 0\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.maxFE = maxFE\n",
    "        self.mutation_factor = mutation_factor\n",
    "        self.crossover_prob = crossover_prob\n",
    "\n",
    "    def initialiseDatabase(self):\n",
    "\n",
    "        sampler = qmc.LatinHypercube(d=self.dimensions)\n",
    "        sample = sampler.random(n=self.pop_size)\n",
    "        population = qmc.scale(sample, self.globalBounds[:, 0], self.globalBounds[:, 1])\n",
    "\n",
    "        for i in range(0, len(population)):\n",
    "            self.feTargets = np.append(self.feTargets, objective_function(population[i]))\n",
    "            self.feFeatures = np.vstack((self.feFeatures, population[i]))\n",
    "\n",
    "        plt.scatter(self.feFeatures[:,0], self.feFeatures[:,1], c = self.feTargets)\n",
    "        plt.title('Initial Population')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "        return population\n",
    "    \n",
    "    \n",
    "    def mutate(self, target_idx):\n",
    "        \"\"\"Mutation using DE/best/1 strategy.\"\"\"\n",
    "        # Choose three random and distinct individuals different from target_idx\n",
    "        indices = [idx for idx in range(self.pop_size) if idx != target_idx]\n",
    "        np.random.shuffle(indices)\n",
    "        r1, r2 , r3= indices[:3]\n",
    "        \n",
    "        # Best individual in current population\n",
    "        best_idx = np.argmin([objective_function(ind) for ind in self.population])\n",
    "        best = self.population[best_idx]\n",
    "        \n",
    "        # Mutant vector: v = best + F * (r1 - r2)\n",
    "        mutant = best + self.mutation_factor * (self.population[r1] - self.population[r2])\n",
    "        \n",
    "        # Ensure mutant vector is within bounds\n",
    "        mutant = np.clip(mutant, self.globalBounds[:, 0], self.globalBounds[:, 1])\n",
    "        \n",
    "        return mutant\n",
    "    \n",
    "    def crossover(self, target, mutant):\n",
    "        \"\"\"Crossover to create trial vector.\n",
    "        This loops through the features in the vector (dimensions) and sees if any of them crossover. \n",
    "        allows the retention of some original vector features but not others. \n",
    "        \"\"\"\n",
    "\n",
    "        trial = np.copy(target)\n",
    "        # print(trial.shape)\n",
    "        # print(mutant.shape)\n",
    "        for i in range(self.dimensions):\n",
    "            if np.random.rand() < self.crossover_prob or i == np.random.randint(self.dimensions):\n",
    "                # print(trial[i], mutant[i])\n",
    "\n",
    "                trial[i] = mutant[i]\n",
    "        return trial\n",
    "    \n",
    "    def runNextAction(self, currentAction):\n",
    "\n",
    "        if currentAction == 0:\n",
    "            print('Running a1!')\n",
    "            newBestFeature, newBestTarget = self.a1()\n",
    "\n",
    "            if newBestTarget < self.x_bestSolution:\n",
    "                self.x_bestSolution = newBestTarget\n",
    "                currentState = 1\n",
    "                r = 1\n",
    "            \n",
    "            else:\n",
    "                currentState = 0\n",
    "                r=0\n",
    "\n",
    "        if currentAction == 1:\n",
    "            print('Running a2!')\n",
    "\n",
    "            newBestFeature, newBestTarget = self.a2()\n",
    "\n",
    "            if newBestTarget < self.x_bestSolution:\n",
    "                self.x_bestSolution = newBestTarget\n",
    "                currentState = 3\n",
    "                r = 1\n",
    "            \n",
    "            else:\n",
    "                currentState = 2\n",
    "                r=0\n",
    "\n",
    "        if currentAction == 2:\n",
    "            print('Running a3!')\n",
    "\n",
    "            newBestFeature, newBestTarget = self.a3()\n",
    "\n",
    "            if newBestTarget < self.x_bestSolution:\n",
    "                self.x_bestSolution = newBestTarget\n",
    "                currentState = 5\n",
    "                r = 1\n",
    "            \n",
    "            else:\n",
    "                currentState = 4\n",
    "                r=0\n",
    "            \n",
    "        if currentAction == 3:\n",
    "            print('Running a4!')\n",
    "\n",
    "            newBestFeature, newBestTarget = self.a4()\n",
    "\n",
    "            if newBestTarget < self.x_bestSolution:\n",
    "                self.x_bestSolution = newBestTarget\n",
    "                currentState = 7\n",
    "                r = 1\n",
    "            \n",
    "            else:\n",
    "                currentState = 6\n",
    "                r=0\n",
    "\n",
    "        return currentState, r, newBestTarget\n",
    "\n",
    "    def mainMenu(self, initialAction):\n",
    "        '''\n",
    "        handle all the q-value and q-table stuff here\n",
    "        such as calculating rewards, probabilities of selecting next states,\n",
    "        and running the next algorithm\n",
    "\n",
    "        set initialAction to be a random number (from 0-3) to select initial algorithm to use\n",
    "        '''\n",
    "\n",
    "        bestIndex = np.argmin(self.feTargets)\n",
    "        self.x_best = self.feFeatures[bestIndex]\n",
    "\n",
    "        self.x_bestSolution = self.feTargets[bestIndex]\n",
    "\n",
    "        currentAction = initialAction\n",
    "\n",
    "        currentState, r, mostRecentValue = self.runNextAction(currentAction)\n",
    "\n",
    "        #calculate softmax selection strategy\n",
    "\n",
    "        actions = np.arange(4)\n",
    "\n",
    "\n",
    "        #loop from here?\n",
    "        iteration = 0\n",
    "        while iteration < self.maxFE:\n",
    "\n",
    "            actionProb = np.empty((1,4))\n",
    "\n",
    "            for i in range(0,4):\n",
    "\n",
    "                actionProb[0,i] = (np.exp(self.qTable[currentState, i])) / np.sum(np.exp(self.qTable[currentState]))\n",
    "\n",
    "            previousState = currentState\n",
    "\n",
    "            # Select an action based on the probabilities in actionProb[1]\n",
    "            next_action = np.random.choice(actions, p=actionProb[0])\n",
    "\n",
    "            currentState, r, mostRecentValue = self.runNextAction(next_action)\n",
    "            print('At iteration: ', iteration, ' current state: ' , currentState)\n",
    "\n",
    "            #calculate the new q value for the action taken in the PREVIOUS state\n",
    "\n",
    "            self.qTable[previousState, next_action] += self.alpha * (r + (self.gamma * np.max(self.qTable[currentState,:]))\n",
    "                                                                    - self.qTable[previousState, next_action])\n",
    "            \n",
    "            print('QTable at iteration ', iteration)\n",
    "            print(self.qTable)\n",
    "\n",
    "            if iteration % 5 == 0:\n",
    "                        plt.scatter(self.feFeatures[:,0], self.feFeatures[:,1], c = self.feTargets)\n",
    "                        plt.title(f'Population at iteration {iteration}')\n",
    "                        plt.colorbar()\n",
    "                        plt.savefig(f'ESAIteration{iteration}.png')\n",
    "\n",
    "                        plt.close()\n",
    "\n",
    "            print(f'Best result at iteration {iteration}', self.x_bestSolution)\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            cax = ax.matshow(np.ndarray.transpose(self.qTable), cmap=\"binary\", vmin = 0, vmax = 1, aspect=1)\n",
    "\n",
    "            # Add color bar to show scale\n",
    "            fig.colorbar(cax)\n",
    "            \n",
    "            # Set custom tick labels for x and y axes\n",
    "            x_labels = ['1', '2', '3', '4', '5', '6', '7', '8']  # 8 columns\n",
    "            y_labels = ['A1', 'A2', 'A3', 'A4']       # 4 rows\n",
    "\n",
    "            ax.set_xticks(np.arange(len(x_labels)))  # Set x-ticks to match number of columns\n",
    "            ax.set_yticks(np.arange(len(y_labels)))  # Set y-ticks to match number of rows\n",
    "            ax.tick_params(top=True, labeltop=True, labelbottom=False, bottom=False)\n",
    "\n",
    "            ax.set_xticklabels(x_labels)  # Set x-tick labels\n",
    "            ax.set_yticklabels(y_labels)  # Set y-tick labels\n",
    "\n",
    "            ax.set_xlabel('State' )\n",
    "            ax.xaxis.set_label_position('top')\n",
    "            ax.set_ylabel(\"Action\")\n",
    "            # Add grid\n",
    "            ax.set_xticks(np.arange(-0.5, len(x_labels), 1), minor=True)\n",
    "            ax.set_yticks(np.arange(-0.5, len(y_labels), 1), minor=True)\n",
    "            ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=2)\n",
    "            ax.tick_params(which=\"minor\", size=0)  # Hide minor ticks but keep grid\n",
    "            plt.text(-0.5,4,f'Previous State = {previousState + 1}')\n",
    "            plt.text(-0.5,4.5,f'Previous Action = {next_action + 1}')\n",
    "            plt.text(-0.5,5,f'Reward = {r}')\n",
    "            plt.text(3,4,f'Current Best Value = {round(self.x_bestSolution, 5)}')\n",
    "            plt.text(3,5,f'Last Found Value = {round(mostRecentValue, 5)}')\n",
    "\n",
    "            plt.savefig(f\"ESAQTablePlots/{iteration}.png\")\n",
    "            plt.close()\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "        #algorithm:\n",
    "        #select initial action randomly\n",
    "        #run action to determine initial state, updating no values yet\n",
    "        #choose new action and run algorithm. This gives FIRST state-action pair\n",
    "        #depending on result, update q value for state action pair. \n",
    "        #repeat. \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def a1(self):\n",
    "\n",
    "        new_population = np.zeros_like(self.population)\n",
    "            \n",
    "        for i in range(self.pop_size):\n",
    "            # print(i)\n",
    "            target = self.population[i]\n",
    "            mutant = self.mutate(i)\n",
    "            trial = self.crossover(target, mutant)\n",
    "            #do not evaluate target/trial vectors, instead just save the trial vectors as the new population\n",
    "            #so they can be evaluated on the global RBF and Lipschitz surrogates later\n",
    "            # new_population[i] = self.select(target, trial)\n",
    "            new_population[i] = trial\n",
    "            \n",
    "            # Update the population\n",
    "        self.population = new_population\n",
    "        # print(new_population.shape)\n",
    "        # pairwise_distances = np.linalg.norm(self.feFeatures[:,np.newaxis] - self.feFeatures, axis=2)\n",
    "        # avg_distance = np.mean(pairwise_distances)\n",
    "        # globalRBF = RBFSurrogateModel(epsilon=1.0)\n",
    "\n",
    "        # globalRBF.fit(self.feFeatures, self.feTargets)\n",
    "\n",
    "        GPModel = GPTrain(self.feFeatures, self.feTargets, meanPrior='zero')\n",
    "\n",
    "        popOnGP = GPEval(GPModel, self.population)\n",
    "\n",
    "        \n",
    "        #evaluating whole landscape on RBF for plotting reasons:\n",
    "        x_range = np.linspace(-5,5,50)\n",
    "        y_range = np.linspace(-5,5,50)\n",
    "        fullRange = list(product(x_range, y_range))\n",
    "        fullRangeArray = np.array(fullRange)\n",
    "        y_pred = GPEval(GPModel, fullRangeArray)\n",
    "\n",
    "\n",
    "        #evaluate current population (children) on RBF\n",
    "        # popOnRBF = globalRBF.predict(self.population)\n",
    "\n",
    "        #function evaluation of best predicted child\n",
    "        best_idx = np.argmin(popOnGP)\n",
    "\n",
    "        bestFeature = self.population[best_idx]\n",
    "\n",
    "        # print('best index =', best_idx)\n",
    "        #evaluate best child and add results to global stores of FE features and targets\n",
    "        self.feTargets = np.append(self.feTargets, objective_function(self.population[best_idx]))\n",
    "        self.feFeatures = np.vstack((self.feFeatures, self.population[best_idx]))\n",
    "\n",
    "        return self.feFeatures[-1], self.feTargets[-1]\n",
    "\n",
    "    \n",
    "    def a2(self):\n",
    "\n",
    "        \n",
    "        bestFeatures = np.empty((self.localPopSize,2))\n",
    "        bestTargets = np.empty(self.localPopSize)\n",
    "\n",
    "        #find c best solutions\n",
    "        bestIndices = np.argsort(self.feTargets)[:self.localPopSize]\n",
    "\n",
    "        for i in range(self.localPopSize):\n",
    "            bestFeatures[i] = self.feFeatures[bestIndices[i]]\n",
    "            bestTargets[i] = self.feTargets[bestIndices[i]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        x_min, x_max = np.min(bestFeatures[:, 0]), np.max(bestFeatures[:, 0])\n",
    "        y_min, y_max = np.min(bestFeatures[:, 1]), np.max(bestFeatures[:, 1])\n",
    "\n",
    "        bounds = [(x_min, x_max), (y_min, y_max)]\n",
    "\n",
    "        # pairwiseDistancesLocal = np.linalg.norm(bestFeatures[:, np.newaxis] - bestFeatures, axis=2)\n",
    "        # avgDistanceLocal = np.mean(pairwiseDistancesLocal)\n",
    "\n",
    "        localGP = GPTrain(bestFeatures, bestTargets, meanPrior='max')\n",
    "\n",
    "        # localRBF = RBFSurrogateModel(epsilon=1.0)\n",
    "        # localRBF.fit(bestFeatures, bestTargets)\n",
    "\n",
    "        # functionEval = localRBF.predict()\n",
    "        localDE = DifferentialEvolution(bounds, localGP )\n",
    "        bestLocalSolution, bestLocalFitness = localDE.optimize()\n",
    "        bestLocalSolution = np.reshape(bestLocalSolution, (2,))\n",
    "\n",
    "        self.feTargets = np.append(self.feTargets, objective_function(bestLocalSolution))\n",
    "        self.feFeatures = np.vstack((self.feFeatures, bestLocalSolution)) \n",
    "\n",
    "        #TODO\n",
    "        #add in step to evaluate best found solution on objective function and return:\n",
    "        return self.feFeatures[-1], self.feTargets[-1]\n",
    "\n",
    "\n",
    "\n",
    "    def a3(self):\n",
    "\n",
    "        #build surrogate using all points in population\n",
    "        crossoverGP = GPTrain(self.feFeatures, self.feTargets, meanPrior='zero')\n",
    "\n",
    "        best_idx = np.argmin(self.feTargets)\n",
    "        bestFeature = self.feFeatures[best_idx]\n",
    "        bestTarget = self.feTargets[best_idx]\n",
    "\n",
    "        RVS = random.sample(range(0, self.dimensions), self.dimensions)\n",
    "\n",
    "        # print(self.feFeatures.shape)\n",
    "        # print(bestFeature)\n",
    "\n",
    "        tempPop = np.full_like((self.feFeatures), bestFeature)\n",
    "\n",
    "        # print(tempPop)\n",
    "\n",
    "        for i in RVS:\n",
    "            # print(i)\n",
    "\n",
    "            tempPop[:,i] = self.feFeatures[:,i]\n",
    "\n",
    "            tempPopEval = GPEval(crossoverGP, tempPop)\n",
    "\n",
    "            tempPopBestIdx = np.argmin(tempPopEval)\n",
    "            if tempPopEval[tempPopBestIdx] > bestTarget:\n",
    "                tempPop = np.full_like((self.feFeatures), tempPop[tempPopBestIdx])\n",
    "                # print('new best value!')\n",
    "\n",
    "        #take final best predicted value and explicitely evaluate\n",
    "        self.feTargets = np.append(self.feTargets, objective_function(tempPop[tempPopBestIdx]))\n",
    "        self.feFeatures = np.vstack((self.feFeatures, tempPop[tempPopBestIdx]))\n",
    "\n",
    "        return self.feFeatures[-1], self.feTargets[-1]\n",
    "\n",
    "\n",
    "    def find_closest_points(self, points, selected_point_index, n):\n",
    "        # Convert points to a NumPy array for easier manipulation\n",
    "        # points = np.array(points)\n",
    "        \n",
    "        # Get the selected point from the array\n",
    "        selected_point = points[selected_point_index]\n",
    "        \n",
    "        # Calculate the Euclidean distance from the selected point to each other point\n",
    "        distances = np.linalg.norm(points - selected_point, axis=1)\n",
    "        \n",
    "        # Exclude the selected point itself by setting its distance to infinity\n",
    "        distances[selected_point_index] = np.inf\n",
    "        \n",
    "        # Find the indices of the n smallest distances\n",
    "        closest_indices = np.argpartition(distances, n)[:n]\n",
    "        \n",
    "        # Get the n closest points\n",
    "        closest_points = points[closest_indices]\n",
    "        \n",
    "        return closest_points\n",
    "    \n",
    "    \n",
    "    def a4(self):\n",
    "\n",
    "        iteration = 0\n",
    "\n",
    "        while iteration < 3:\n",
    "\n",
    "            print('iteration = ', iteration)\n",
    "\n",
    "            #this handles x_best updating\n",
    "            bestIndex = np.argmin(self.feTargets)\n",
    "            x_best = self.feFeatures[bestIndex]\n",
    "\n",
    "            x_bestSolution = self.feTargets[bestIndex]\n",
    "\n",
    "            if iteration == 0:\n",
    "\n",
    "                nPoints = self.dimensions * 5\n",
    "\n",
    "                closestPoints = self.find_closest_points(self.feFeatures, bestIndex, nPoints)\n",
    "\n",
    "                x_min, x_max = np.min(closestPoints[:, 0]), np.max(closestPoints[:, 0])\n",
    "                y_min, y_max = np.min(closestPoints[:, 1]), np.max(closestPoints[:, 1])\n",
    "\n",
    "                # print('x min max', x_min, x_max)\n",
    "                # print('y min max', y_min, y_max)\n",
    "\n",
    "\n",
    "                sigma = np.empty((1,self.dimensions))\n",
    "\n",
    "                # print(sigma.shape)\n",
    "\n",
    "                #hard coded to two dimensions for now\n",
    "                sigma[0,0] = ((x_max - x_min)/2)\n",
    "                sigma[0,1] = ((y_max) - (y_min)/2)\n",
    "\n",
    "                # print('sigma', sigma)\n",
    "\n",
    "                # print('xbest', x_best)\n",
    "\n",
    "            lower_bound_trust = x_best - sigma\n",
    "            upper_bound_trust = x_best + sigma\n",
    "\n",
    "            # print('lower bound trust shape:  ', lower_bound_trust.shape)\n",
    "    \n",
    "            # print(lower_bound_trust)\n",
    "\n",
    "            trustRegionBounds = [(lower_bound_trust[0,0], upper_bound_trust[0,0]), (lower_bound_trust[0,1], upper_bound_trust[0,1])]\n",
    "\n",
    "\n",
    "            in_area = (self.feFeatures[:, 0] >= lower_bound_trust[0,0]) & (self.feFeatures[:, 0] <= upper_bound_trust[0,0]) & \\\n",
    "                    (self.feFeatures[:, 1] >= lower_bound_trust[0,1]) & (self.feFeatures[:, 1] <= upper_bound_trust[0,1])\n",
    "            \n",
    "            # print(in_area)\n",
    "\n",
    "            #in_area is a 'boolean mask', which evaluates to True if all above conditions are achieved. \n",
    "            #when setting the points below it automatically chooses only ones which are true. \n",
    "\n",
    "            trustRegionFeatures = self.feFeatures[in_area]\n",
    "            trustRegionTargets = self.feTargets[in_area]\n",
    "\n",
    "            try:\n",
    "            #build surrogate on points in the trust region\n",
    "                trustRegionGP = GPTrain(trustRegionFeatures, trustRegionTargets, meanPrior='max')\n",
    "\n",
    "                trustRegionDE = DifferentialEvolution(trustRegionBounds, trustRegionGP)\n",
    "                trustBestSolution, trustBestFitness = trustRegionDE.optimize()\n",
    "\n",
    "                trustBestSolution = np.reshape(trustBestSolution, (2,))\n",
    "\n",
    "                # print('trust region best Solution', trustBestSolution)\n",
    "\n",
    "\n",
    "                trustBestFE =  objective_function(trustBestSolution)\n",
    "\n",
    "                self.feTargets = np.append(self.feTargets, objective_function(trustBestSolution))\n",
    "                self.feFeatures = np.vstack((self.feFeatures, trustBestSolution)) \n",
    "\n",
    "                #calculate trust ratio\n",
    "\n",
    "                rho_k = (x_bestSolution - trustBestFE)/(x_bestSolution - trustBestFitness)\n",
    "\n",
    "                # print('rho_k = ', rho_k)\n",
    "                # print('old sigma =', sigma)\n",
    "\n",
    "                epsilon = 1.5\n",
    "\n",
    "                if rho_k < 0.25:\n",
    "                    sigma = 0.25 * sigma\n",
    "\n",
    "                elif rho_k > 0.25 and rho_k < 0.75:\n",
    "                    sigma = sigma #is there something smarter i can do?\n",
    "\n",
    "                elif rho_k > 0.75:\n",
    "                    sigma = epsilon * sigma\n",
    "\n",
    "                # print('new sigma = ', sigma)\n",
    "\n",
    "                # plt.scatter(self.feFeatures[:,0], self.feFeatures[:,1], c = self.feTargets)\n",
    "                # plt.title('Evaluated Population')\n",
    "                # plt.colorbar()\n",
    "                # plt.show()\n",
    "\n",
    "                iteration += 1\n",
    "            except RuntimeError:\n",
    "                print('Error in training GP Surrogate, skipping...')\n",
    "                iteration +=1\n",
    "            \n",
    "            #return however many iterations worth of features/targets\n",
    "        return self.feFeatures[-1], self.feTargets[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectedImprovement(currentGP, feature, bestY, epsilon):\n",
    "    yPred, yStd = GPEval(currentGP, feature)\n",
    "\n",
    "    #TODO check that signs are the correct way round in ei and z equations.\n",
    "\n",
    "    z = (bestY - yPred - epsilon)/yStd\n",
    "    ei = ((bestY - yPred - epsilon) * norm.cdf(z)) + yStd*norm.pdf(z)\n",
    "    return ei\n",
    "\n",
    "\n",
    "def upperConfidenceBounds(currentGP, feature, bestY, Lambda):\n",
    "    yPred, yStd = GPEval(currentGP, feature)\n",
    "\n",
    "    a = yPred + (Lambda * yStd)\n",
    "\n",
    "    return a\n",
    "\n",
    "def probabilityOfImprovement(currentGP, feature, bestY, epsilon):\n",
    "    #NO EPSILON IN THIS EQUATION. THATS ONLY FOR EI\n",
    "    #THIS Z EQUATION IS FOR MAXIMISATION.\n",
    "    yPred, yStd = GPEval(currentGP, feature)\n",
    "    z = (bestY - yPred)/yStd\n",
    "    pi = norm.cdf(z)\n",
    "\n",
    "    return pi\n",
    "\n",
    "class bayesianOptimiser:\n",
    "    def __init__(self, bounds, pop_size ):\n",
    "        self.globalBounds = np.array(bounds)\n",
    "        self.dimensions = len(bounds)\n",
    "        self.feFeatures = np.empty((0,2))\n",
    "        self.pop_size = pop_size\n",
    "\n",
    "        self.feTargets = np.empty(0) \n",
    "        self.population = self.initialiseDatabase()\n",
    "        self.x_bestSolution = 0\n",
    "        self.bestEI = 100\n",
    "\n",
    "\n",
    "    def initialiseDatabase(self):\n",
    "\n",
    "        sampler = qmc.LatinHypercube(d=self.dimensions)\n",
    "        sample = sampler.random(n=self.pop_size)\n",
    "        population = qmc.scale(sample, self.globalBounds[:, 0], self.globalBounds[:, 1])\n",
    "\n",
    "        for i in range(0, len(population)):\n",
    "            self.feTargets = np.append(self.feTargets, objective_function(population[i]))\n",
    "            self.feFeatures = np.vstack((self.feFeatures, population[i]))\n",
    "\n",
    "        plt.scatter(self.feFeatures[:,0], self.feFeatures[:,1], c = self.feTargets)\n",
    "        plt.title('Initial Population')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "        return population\n",
    "\n",
    "\n",
    "    def runOptimiser(self):\n",
    "        iteration = 0\n",
    "\n",
    "        while self.bestEI > 1e-5:\n",
    "            best_idx = np.argmin(self.feTargets)\n",
    "            bestFeature = self.feFeatures[best_idx]\n",
    "            bestTarget = self.feTargets[best_idx]\n",
    "            print(bestTarget)\n",
    "\n",
    "            globalGP = GPTrain(self.feFeatures, self.feTargets, meanPrior='zero')\n",
    "\n",
    "            #evaluating whole landscape on RBF for plotting reasons:\n",
    "            x_range = np.linspace(-5,5,100)\n",
    "            y_range = np.linspace(-5,5,100)\n",
    "            fullRange = list(product(x_range, y_range))\n",
    "            fullRangeArray = np.array(fullRange)\n",
    "            y_pred, ystd = GPEval(globalGP, fullRangeArray)\n",
    "\n",
    "            # print(fullRangeArray.shape, y_pred.shape)\n",
    "\n",
    "            plt.scatter(fullRangeArray[:,0], fullRangeArray[:,1], c=y_pred)\n",
    "            plt.title(\"Global Surrogate\")\n",
    "            plt.colorbar()\n",
    "            plt.clim(0,14)\n",
    "            plt.savefig('eiGS.png')\n",
    "            plt.close()\n",
    "\n",
    "            eiDE = DifferentialEvolution(globalGP, self.globalBounds, bestTarget )\n",
    "            newSolution, newFitness = eiDE.optimize()\n",
    "\n",
    "            self.feTargets = np.append(self.feTargets, objective_function(newSolution))\n",
    "            self.feFeatures = np.vstack((self.feFeatures, newSolution))\n",
    "\n",
    "            print('Best found solution = ', bestTarget)\n",
    "\n",
    "            surrogate = Image.open('eiGS.png')\n",
    "            population = Image.open('eiDE.png')\n",
    "\n",
    "            width, height = population.size\n",
    "            combinedImage = Image.new('RGB', (2 * width, height), \"WHITE\")\n",
    "            combinedImage.paste(population, (0, 0))\n",
    "            combinedImage.paste(surrogate, (width, 0))\n",
    "\n",
    "            combinedImage.save(f'BOEIPlots/{iteration}.png')\n",
    "\n",
    "            self.bestEI = newFitness\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "        #\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenFOAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
