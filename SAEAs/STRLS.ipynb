{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from itertools import product\n",
    "from scipy.stats import qmc  # For Latin Hypercube Sampling\n",
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "from PIL import Image\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, meanPrior):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        if meanPrior == 'max':\n",
    "            # self.mean_module = gpytorch.means.ZeroMean()\n",
    "            self.mean_module = gpytorch.means.ConstantMean()\n",
    "            # self.mean_module.constant = torch.nn.Parameter(torch.tensor(torch.max(train_y)))\n",
    "            self.mean_module.constant.data = torch.tensor(torch.max(train_y))\n",
    "\n",
    "        else:\n",
    "            # self.mean_module = gpytorch.means.ConstantMean(constant_prior=torch.max(train_y))\n",
    "            self.mean_module = gpytorch.means.ZeroMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "def GPTrain(features, targets, meanPrior):\n",
    "\n",
    "    tensorSamplesXY = torch.from_numpy(features)\n",
    "    tensorSamplesZ = torch.from_numpy(targets)\n",
    "\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood() \n",
    "    model = ExactGPModel(tensorSamplesXY, tensorSamplesZ, likelihood, meanPrior)\n",
    "    likelihood.noise = 1e-4\n",
    "    likelihood.noise_covar.raw_noise.requires_grad_(False)\n",
    "\n",
    "    training_iter = 250\n",
    "    # Find optimal model hyperparameters\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.05)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(tensorSamplesXY)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, tensorSamplesZ)\n",
    "        loss.backward()\n",
    "        # print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "        #     i + 1, training_iter, loss.item(),\n",
    "        #     model.covar_module.base_kernel.lengthscale.item(), #.kernels[0] after base_kernel if have multiple kernels\n",
    "        #     model.likelihood.noise.item()\n",
    "        # ))\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def GPEval(model, newFeatures):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        observed_pred = model(torch.from_numpy(newFeatures))\n",
    "\n",
    "    mean_pred = observed_pred.mean.numpy()\n",
    "\n",
    "    return mean_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DifferentialEvolution:\n",
    "    def __init__(self, bounds, objective_function, iterationNumber, pop_size=50, mutation_factor=0.8, crossover_prob=0.7, max_generations=200, method='random'):\n",
    "        \"\"\"\n",
    "        Initialize the Differential Evolution (DE) optimizer.\n",
    "        \n",
    "        Parameters:\n",
    "        bounds (list of tuple): List of (min, max) bounds for each dimension.\n",
    "        pop_size (int): Number of candidate solutions in the population.\n",
    "        mutation_factor (float): Scaling factor for mutation [0, 2].\n",
    "        crossover_prob (float): Crossover probability [0, 1].\n",
    "        max_generations (int): Maximum number of generations to evolve.\n",
    "        method (str): Population initialization method ('random' or 'lhs').\n",
    "        \"\"\"\n",
    "        self.bounds = np.array(bounds)\n",
    "        self.dimensions = len(bounds)\n",
    "        self.pop_size = pop_size\n",
    "        self.mutation_factor = mutation_factor\n",
    "        self.crossover_prob = crossover_prob\n",
    "        self.max_generations = max_generations\n",
    "        self.method = method\n",
    "        \n",
    "        # Initialize population\n",
    "        self.population = self.initialize_population()\n",
    "        self.best_solution = None\n",
    "        self.best_fitness = np.inf\n",
    "        self.objective_function = objective_function\n",
    "        self.iteration = iterationNumber\n",
    "    \n",
    "    def initialize_population(self):\n",
    "        \"\"\"Initialize population using random sampling or Latin Hypercube Sampling.\"\"\"\n",
    "        if self.method == 'lhs':\n",
    "            # Latin Hypercube Sampling\n",
    "            sampler = qmc.LatinHypercube(d=self.dimensions)\n",
    "            sample = sampler.random(n=self.pop_size)\n",
    "            population = qmc.scale(sample, self.bounds[:, 0], self.bounds[:, 1])\n",
    "        else:\n",
    "            # Random Sampling\n",
    "            population = np.random.rand(self.pop_size, self.dimensions)\n",
    "            for i in range(self.dimensions):\n",
    "                population[:, i] = self.bounds[i, 0] + population[:, i] * (self.bounds[i, 1] - self.bounds[i, 0])\n",
    "        \n",
    "        # print(population.shape)\n",
    "        return population\n",
    "    \n",
    "    def mutate(self, target_idx):\n",
    "        \"\"\"Mutation using DE/best/1 strategy.\"\"\"\n",
    "        # Choose three random and distinct individuals different from target_idx\n",
    "        indices = [idx for idx in range(self.pop_size) if idx != target_idx]\n",
    "        np.random.shuffle(indices)\n",
    "        r1, r2 , r3= indices[:3]\n",
    "        \n",
    "        # Best individual in current population\n",
    "\n",
    "        # print(self.population.shape)\n",
    "\n",
    "        #TODO  instead of this list comprehension bollocks just evaluate them all at once\n",
    "        #as thats what i think it wants, then find the minimum of the results. \n",
    "\n",
    "\n",
    "        predictedValues = GPEval(self.objective_function, self.population)\n",
    "\n",
    "        best_idx = np.argsort(predictedValues)[:1]\n",
    "\n",
    "        best = self.population[best_idx]\n",
    "\n",
    "        # best_idx = np.argmin([self.objective_function.predict(ind) for ind in self.population])\n",
    "        # best = self.population[best_idx]\n",
    "        \n",
    "        # Mutant vector: v = best + F * (r1 - r2)\n",
    "        mutant = best + self.mutation_factor * (self.population[r1] - self.population[r2])\n",
    "        \n",
    "        # Ensure mutant vector is within bounds\n",
    "        mutant = np.clip(mutant, self.bounds[:, 0], self.bounds[:, 1])\n",
    "        \n",
    "        return mutant\n",
    "    \n",
    "    def crossover(self, target, mutant):\n",
    "        \"\"\"Crossover to create trial vector.\"\"\"\n",
    "        trial = np.copy(target)\n",
    "        # print(trial.shape)\n",
    "        # print(mutant.shape)\n",
    "        for i in range(self.dimensions):\n",
    "            if np.random.rand() < self.crossover_prob or i == np.random.randint(self.dimensions):\n",
    "                # print(trial[i], mutant[i])\n",
    "                trial[i] = mutant[i]\n",
    "        return trial\n",
    "    \n",
    "    def select(self, target, trial):\n",
    "        \"\"\"Selection: Return the individual with the better fitness.\"\"\"\n",
    "        if self.objective_function.predict(trial) < self.objective_function.predict(target):\n",
    "            return trial\n",
    "        return target\n",
    "\n",
    "    def select(self, target, trial):\n",
    "        \"\"\"Selection: Return the individual with the better fitness.\"\"\"\n",
    "        if GPEval(self.objective_function, trial) < GPEval(self.objective_function, target):\n",
    "            return trial\n",
    "        return target\n",
    "    \n",
    "    def optimize(self):\n",
    "        \"\"\"Run the Differential Evolution optimization.\"\"\"\n",
    "        # x_range = np.linspace(-5, 5, 100)\n",
    "        # y_range = np.linspace(-5, 5, 100)\n",
    "        # X, Y = np.meshgrid(x_range, y_range)\n",
    "        # Z = ackley_function(X, Y)\n",
    "        x_range = np.linspace(self.bounds[0,0], self.bounds[0,1],50)\n",
    "        y_range = np.linspace(self.bounds[1,0], self.bounds[1,1],50)\n",
    "        fullRange = list(product(x_range, y_range))\n",
    "        fullRangeArray = np.array(fullRange)\n",
    "        # y_pred = self.objective_function.predict(fullRangeArray)\n",
    "        y_pred = GPEval(self.objective_function, fullRangeArray)\n",
    "\n",
    "        for generation in range(self.max_generations):\n",
    "            new_population = np.zeros_like(self.population)\n",
    "            allTrials = np.zeros_like(self.population)\n",
    "            allTargets = np.zeros_like(self.population)\n",
    "            # print(self.population.shape)\n",
    "            for i in range(self.pop_size):\n",
    "                target = self.population[i]\n",
    "                # print('break')\n",
    "                # print(i)\n",
    "                mutant = self.mutate(i)\n",
    "                # print(mutant)\n",
    "                mutant = np.reshape(mutant, (2,))\n",
    "                # print(mutant)\n",
    "                trial = self.crossover(target, mutant)\n",
    "                trial = np.reshape(trial, (1,-1))\n",
    "                target = np.reshape(target, (1,-1))\n",
    "                # print('for select', trial.shape, target.shape)\n",
    "                new_population[i] = self.select(target, trial)\n",
    "            \n",
    "            # Update the population\n",
    "            self.population = new_population\n",
    "            \n",
    "            # Track the best solution\n",
    "            # best_idx = np.argmin([self.objective_function.predict(ind) for ind in self.population])\n",
    "            # best_fitness = self.objective_function.predict(self.population[best_idx])\n",
    "            \n",
    "            # predictedValues = self.objective_function.predict(self.population)\n",
    "            predictedValues = GPEval(self.objective_function, self.population)\n",
    "\n",
    "            best_idx = np.argsort(predictedValues)[:1]\n",
    "\n",
    "            # best_fitness = self.objective_function.predict(self.population[best_idx])\n",
    "            best_fitness = GPEval(self.objective_function, self.population[best_idx])\n",
    "\n",
    "            if best_fitness < self.best_fitness:\n",
    "                self.best_fitness = best_fitness\n",
    "                self.best_solution = self.population[best_idx]\n",
    "            \n",
    "            # plt.contourf(x_range, y_range, y_pred, levels=50, cmap='viridis')\n",
    "        plt.scatter(fullRangeArray[:,0], fullRangeArray[:,1], c = y_pred)\n",
    "\n",
    "        plt.scatter(self.population[:, 0], self.population[:, 1], color='red', label='Final Population', s=5)\n",
    "        # # plt.scatter(best_solution[0], best_solution[1], color='blue', label='Best Solution', s=100)\n",
    "        # plt.legend()\n",
    "        plt.title(\"Trust-Region Surrogate\")\n",
    "        plt.colorbar()\n",
    "        plt.clim(0,14)\n",
    "        plt.xlim(self.bounds[0,0], self.bounds[0,1])\n",
    "        plt.ylim(self.bounds[1,0], self.bounds[1,1])\n",
    "        plt.savefig('trustRegion.png')\n",
    "        # plt.show()\n",
    "        plt.close()\n",
    "        # # # Debug information\n",
    "        # print(f\"Generation {generation + 1}: Best RBF Fitness = {self.best_fitness}\")\n",
    "        \n",
    "        return self.best_solution, self.best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function (Ackley function used as an example)\n",
    "def ackley_function(x, y, a=20, b=0.2, c=2 * np.pi):\n",
    "    term1 = -a * np.exp(-b * np.sqrt(0.5 * (x**2 + y**2)))\n",
    "    term2 = -np.exp(0.5 * (np.cos(c * x) + np.cos(c * y)))\n",
    "    return term1 + term2 + a + np.exp(1)\n",
    "\n",
    "# Objective function (Ackley function used as an example)\n",
    "# def ackley_function(x, y, a=20, b=0.2, c=2 * np.pi):\n",
    "#     z = np.sin(x)+(x*np.cos(0.5*y))\n",
    "#     return z\n",
    "\n",
    "def objective_function(vec):\n",
    "    \"\"\"Objective function wrapper for optimization.\n",
    "    Args:\n",
    "        vec (np.ndarray): A vector representing candidate solution (x, y).\n",
    "    Returns:\n",
    "        float: Fitness value of the solution.\n",
    "    \"\"\"\n",
    "    x, y = vec\n",
    "    return ackley_function(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STRLS:\n",
    "    def __init__(self, bounds, pop_size, localPopSize):\n",
    "        self.globalBounds = np.array(bounds)\n",
    "        self.dimensions = len(bounds)\n",
    "        self.pop_size = pop_size\n",
    "        self.feFeatures = np.empty((0,2))\n",
    "        self.feTargets = np.empty(0) \n",
    "        # self.k = k\n",
    "        self.population = self.initialiseDatabase()\n",
    "        self.localPopSize = localPopSize\n",
    "\n",
    "        \n",
    "\n",
    "    def initialiseDatabase(self):\n",
    "\n",
    "        sampler = qmc.LatinHypercube(d=self.dimensions)\n",
    "        sample = sampler.random(n=self.pop_size)\n",
    "        population = qmc.scale(sample, self.globalBounds[:, 0], self.globalBounds[:, 1])\n",
    "\n",
    "        for i in range(0, len(population)):\n",
    "            self.feTargets = np.append(self.feTargets, objective_function(population[i]))\n",
    "            self.feFeatures = np.vstack((self.feFeatures, population[i]))\n",
    "\n",
    "        plt.scatter(self.feFeatures[:,0], self.feFeatures[:,1], c = self.feTargets)\n",
    "        plt.title('Initial Population')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "        return population\n",
    "    \n",
    "    # def findLocalBounds(self):\n",
    "\n",
    "    #     bestFeatures = np.empty((self.localPopSize,2))\n",
    "    #     bestTargets = np.empty(self.localPopSize)\n",
    "\n",
    "    #     #find c best solutions\n",
    "    #     bestIndices = np.argsort(self.feTargets)[:self.localPopSize]\n",
    "\n",
    "    #     for i in range(self.localPopSize):\n",
    "    #         bestFeatures[i] = self.feFeatures[bestIndices[i]]\n",
    "    #         bestTargets[i] = self.feTargets[bestIndices[i]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #     x_min, x_max = np.min(bestFeatures[:, 0]), np.max(bestFeatures[:, 0])\n",
    "    #     y_min, y_max = np.min(bestFeatures[:, 1]), np.max(bestFeatures[:, 1])\n",
    "\n",
    "\n",
    "    #     #this is [lb,ub]\n",
    "    #     localBounds = [(x_min, x_max), (y_min, y_max)]\n",
    "\n",
    "    #     return localBounds\n",
    "    \n",
    "    def find_closest_points(self, points, selected_point_index, n):\n",
    "        # Convert points to a NumPy array for easier manipulation\n",
    "        # points = np.array(points)\n",
    "        \n",
    "        # Get the selected point from the array\n",
    "        selected_point = points[selected_point_index]\n",
    "        \n",
    "        # Calculate the Euclidean distance from the selected point to each other point\n",
    "        distances = np.linalg.norm(points - selected_point, axis=1)\n",
    "        \n",
    "        # Exclude the selected point itself by setting its distance to infinity\n",
    "        distances[selected_point_index] = np.inf\n",
    "        \n",
    "        # Find the indices of the n smallest distances\n",
    "        closest_indices = np.argpartition(distances, n)[:n]\n",
    "        \n",
    "        # Get the n closest points\n",
    "        closest_points = points[closest_indices]\n",
    "        \n",
    "        return closest_points\n",
    "    \n",
    "    \n",
    "    def initialTrustRegion(self, localBounds):\n",
    "\n",
    "        iteration = 0\n",
    "\n",
    "        while iteration < 50:\n",
    "\n",
    "            print('iteration = ', iteration)\n",
    "\n",
    "            #this handles x_best updating\n",
    "            bestIndex = np.argmin(self.feTargets)\n",
    "            x_best = self.feFeatures[bestIndex]\n",
    "\n",
    "            x_bestSolution = self.feTargets[bestIndex]\n",
    "\n",
    "            if iteration == 0:\n",
    "\n",
    "                nPoints = self.dimensions * 5\n",
    "\n",
    "                closestPoints = self.find_closest_points(self.feFeatures, bestIndex, nPoints)\n",
    "\n",
    "                # print('closest points', closestPoints)\n",
    "\n",
    "                x_min, x_max = np.min(closestPoints[:, 0]), np.max(closestPoints[:, 0])\n",
    "                y_min, y_max = np.min(closestPoints[:, 1]), np.max(closestPoints[:, 1])\n",
    "\n",
    "                print('x min max', x_min, x_max)\n",
    "                print('y min max', y_min, y_max)\n",
    "\n",
    "\n",
    "                sigma = np.empty((1,self.dimensions))\n",
    "\n",
    "                print(sigma.shape)\n",
    "\n",
    "                #hard coded to two dimensions for now\n",
    "                #remove abs because it makes no sense\n",
    "\n",
    "                sigma[0,0] = ((x_max - x_min)/2)\n",
    "                sigma[0,1] = ((y_max) - (y_min)/2)\n",
    "\n",
    "                # sigma[0,0] = ((abs(x_max) - abs(x_min)))\n",
    "                # sigma[0,1] = ((abs(y_max) - abs(y_min)))\n",
    "\n",
    "                print('sigma', sigma)\n",
    "\n",
    "                print('xbest', x_best)\n",
    "\n",
    "            lower_bound_trust = x_best - sigma\n",
    "            upper_bound_trust = x_best + sigma\n",
    "\n",
    "            print('lower bound trust shape:  ', lower_bound_trust.shape)\n",
    "    \n",
    "            print(lower_bound_trust)\n",
    "\n",
    "            #TODO fix this next bit\n",
    "\n",
    "            # lower_bound_trust = np.maximum(lower_bound_trust, localBounds[0, :])\n",
    "            # upper_bound_trust = np.minimum(upper_bound_trust, localBounds[1, :])\n",
    "\n",
    "\n",
    "            #this is wrong\n",
    "            # trustRegionBounds = [(lower_bound_trust[0,0], lower_bound_trust[0,1]), (upper_bound_trust[0,0], upper_bound_trust[0,1])]\n",
    "\n",
    "            #this might be more correct\n",
    "            trustRegionBounds = [(lower_bound_trust[0,0], upper_bound_trust[0,0]), (lower_bound_trust[0,1], upper_bound_trust[0,1])]\n",
    "\n",
    "\n",
    "            # print('trust region bounds', trustRegionBounds)\n",
    "\n",
    "            #find points in that area:\n",
    "\n",
    "            #check which values are actuall my upper and lower bounds here\n",
    "\n",
    "            # print(lower_bound_trust[0,0], upper_bound_trust[0,0])\n",
    "            # print('..', lower_bound_trust[0,1], upper_bound_trust[0,1])\n",
    "\n",
    "            in_area = (self.feFeatures[:, 0] >= lower_bound_trust[0,0]) & (self.feFeatures[:, 0] <= upper_bound_trust[0,0]) & \\\n",
    "                    (self.feFeatures[:, 1] >= lower_bound_trust[0,1]) & (self.feFeatures[:, 1] <= upper_bound_trust[0,1])\n",
    "            \n",
    "            # print(in_area)\n",
    "\n",
    "            #in_area is a 'boolean mask', which evaluates to True if all above conditions are achieved. \n",
    "            #when setting the points below it automatically chooses only ones which are true. \n",
    "\n",
    "            trustRegionFeatures = self.feFeatures[in_area]\n",
    "            trustRegionTargets = self.feTargets[in_area]\n",
    "\n",
    "            # print(trustRegionFeatures)\n",
    "            # print(trustRegionTargets)\n",
    "\n",
    "            #build surrogate on points in the trust region\n",
    "            trustRegionGP = GPTrain(trustRegionFeatures, trustRegionTargets, meanPrior='max')\n",
    "\n",
    "            trustRegionDE = DifferentialEvolution(trustRegionBounds, trustRegionGP, iteration)\n",
    "            trustBestSolution, trustBestFitness = trustRegionDE.optimize()\n",
    "\n",
    "            trustBestSolution = np.reshape(trustBestSolution, (2,))\n",
    "\n",
    "            print('trust region best Solution', trustBestSolution)\n",
    "\n",
    "\n",
    "            trustBestFE =  objective_function(trustBestSolution)\n",
    "\n",
    "            self.feTargets = np.append(self.feTargets, objective_function(trustBestSolution))\n",
    "            self.feFeatures = np.vstack((self.feFeatures, trustBestSolution)) \n",
    "\n",
    "            #calculate trust ratio\n",
    "\n",
    "            #normalise data before trust ratio calculation\n",
    "            minTarget = np.min(self.feTargets)\n",
    "            maxTarget = np.max(self.feTargets)\n",
    "\n",
    "            x_bestSolutionNorm = (x_bestSolution - minTarget)/(maxTarget - minTarget)\n",
    "            trustBestFENorm = (trustBestFE - minTarget)/(maxTarget - minTarget)\n",
    "            trustBestFitnessNorm = (trustBestFitness - minTarget)/(maxTarget - minTarget)\n",
    "\n",
    "            rho_k = (x_bestSolutionNorm - trustBestFENorm)/(x_bestSolutionNorm - trustBestFitnessNorm)\n",
    "            # rho_k = (x_bestSolution - trustBestFE)/(x_bestSolution - trustBestFitness)\n",
    "\n",
    "            print(x_bestSolution, 'xbestsolution')\n",
    "\n",
    "            print('predicted result = ', trustBestFitness, 'actual result = ', trustBestFE)\n",
    "\n",
    "            # rho_k = trustBestFE/trustBestFitness\n",
    "\n",
    "            print('rho_k = ', rho_k)\n",
    "            print('old sigma =', sigma)           \n",
    "\n",
    "            epsilon = 1.5\n",
    "\n",
    "            if rho_k < 0.25:\n",
    "                sigma = 0.25 * sigma\n",
    "\n",
    "            elif rho_k > 0.25 and rho_k < 0.75:\n",
    "                sigma = sigma #is there something smarter i can do?\n",
    "\n",
    "            elif rho_k > 0.75:\n",
    "                sigma = epsilon * sigma\n",
    "\n",
    "            print('new sigma = ', sigma)\n",
    "\n",
    "            bestNIndices = np.argpartition(self.feTargets, 10)[:10]\n",
    "            bestNFeatures = self.feFeatures[bestNIndices]\n",
    "            bestNTargets = self.feTargets[bestNIndices]\n",
    "\n",
    "            plt.scatter(bestNFeatures[:,0], bestNFeatures[:,1], c = bestNTargets)\n",
    "            plt.title('Best 10 Points')\n",
    "            plt.colorbar()\n",
    "            plt.clim(0,14)\n",
    "            plt.figtext(0.7,-0.05,f'Global Best =  {round(x_bestSolution, 5)}')\n",
    "            plt.figtext(0.7,-0.1,f'Previous Result = {round(trustBestFE,5)}')\n",
    "            plt.figtext(0.7,-0.15,f'rho_k =  {round(rho_k[0], 5)}')\n",
    "\n",
    "            plt.savefig('TRSPop.png', bbox_inches=\"tight\")\n",
    "            \n",
    "            # plt.savefig('TRSPop.png')\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "            surrogate = Image.open('trustRegion.png')\n",
    "            population = Image.open('TRSPop.png')\n",
    "\n",
    "            width, height = population.size\n",
    "            combinedImage = Image.new('RGB', (2 * width, height), \"WHITE\")\n",
    "            combinedImage.paste(population, (0, 0))\n",
    "            combinedImage.paste(surrogate, (width, 0))\n",
    "\n",
    "            combinedImage.save(f'TRSPlots/{iteration}.png')\n",
    "            iteration += 1\n",
    "\n",
    "\n",
    "\n",
    "        #add looping for sigma. \n",
    "\n",
    "\n",
    "        #need to tidy this up so the loop works - remove initialisation of sigma etc...\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration =  0\n",
      "x min max -2.9231011732311147 1.945168452232875\n",
      "y min max -2.3178159201815203 1.4288003990314637\n",
      "(1, 2)\n",
      "sigma [[2.43413481 2.58770836]]\n",
      "xbest [-0.38487291 -0.07944564]\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-2.81900773 -2.667154  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8p/wlgb17ln00dg_lln7zq_3gpw0000gn/T/ipykernel_53315/4061782729.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.mean_module.constant.data = torch.tensor(torch.max(train_y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trust region best Solution [-0.05297407 -0.07393429]\n",
      "2.733189642959911 xbestsolution\n",
      "predicted result =  [2.55781418] actual result =  0.46567448239485687\n",
      "rho_k =  [12.92948931]\n",
      "old sigma = [[2.43413481 2.58770836]]\n",
      "new sigma =  [[3.65120222 3.88156254]]\n",
      "iteration =  1\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-3.70417629 -3.95549683]]\n",
      "trust region best Solution [ 0.1687481  -0.16074625]\n",
      "0.46567448239485687 xbestsolution\n",
      "predicted result =  [-0.09855971] actual result =  1.7010178412990524\n",
      "rho_k =  [-2.18941597]\n",
      "old sigma = [[3.65120222 3.88156254]]\n",
      "new sigma =  [[0.91280055 0.97039063]]\n",
      "iteration =  2\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-0.96577462 -1.04432492]]\n",
      "trust region best Solution [-0.04385672 -0.06419511]\n",
      "0.46567448239485687 xbestsolution\n",
      "predicted result =  [0.46111838] actual result =  0.3744020752370827\n",
      "rho_k =  [20.03299287]\n",
      "old sigma = [[0.91280055 0.97039063]]\n",
      "new sigma =  [[1.36920083 1.45558595]]\n",
      "iteration =  3\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-1.41305756 -1.51978106]]\n",
      "trust region best Solution [-0.00322562  0.0267938 ]\n",
      "0.3744020752370827 xbestsolution\n",
      "predicted result =  [0.03257024] actual result =  0.09561027444275583\n",
      "rho_k =  [0.81558174]\n",
      "old sigma = [[1.36920083 1.45558595]]\n",
      "new sigma =  [[2.05380125 2.18337893]]\n",
      "iteration =  4\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-2.05702687 -2.15658513]]\n",
      "trust region best Solution [-0.00905068  0.03067659]\n",
      "0.09561027444275583 xbestsolution\n",
      "predicted result =  [0.09352949] actual result =  0.11748839016860346\n",
      "rho_k =  [-10.51435022]\n",
      "old sigma = [[2.05380125 2.18337893]]\n",
      "new sigma =  [[0.51345031 0.54584473]]\n",
      "iteration =  5\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-0.51667593 -0.51905093]]\n",
      "trust region best Solution [0.01888429 0.00810852]\n",
      "0.09561027444275583 xbestsolution\n",
      "predicted result =  [0.06321428] actual result =  0.06934027857912328\n",
      "rho_k =  [0.81090268]\n",
      "old sigma = [[0.51345031 0.54584473]]\n",
      "new sigma =  [[0.77017547 0.8187671 ]]\n",
      "iteration =  6\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-0.75129117 -0.81065858]]\n",
      "trust region best Solution [0.01710129 0.00889564]\n",
      "0.06934027857912328 xbestsolution\n",
      "predicted result =  [0.06900591] actual result =  0.06439088065816323\n",
      "rho_k =  [14.80242724]\n",
      "old sigma = [[0.77017547 0.8187671 ]]\n",
      "new sigma =  [[1.1552632  1.22815065]]\n",
      "iteration =  7\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-1.13816191 -1.219255  ]]\n",
      "trust region best Solution [0.01897605 0.00913608]\n",
      "0.06439088065816323 xbestsolution\n",
      "predicted result =  [0.06682821] actual result =  0.07134231047395945\n",
      "rho_k =  [2.85206845]\n",
      "old sigma = [[1.1552632  1.22815065]]\n",
      "new sigma =  [[1.7328948  1.84222597]]\n",
      "iteration =  8\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-1.71579352 -1.83333033]]\n",
      "trust region best Solution [0.02559524 0.01438831]\n",
      "0.06439088065816323 xbestsolution\n",
      "predicted result =  [0.06606407] actual result =  0.1058671031976961\n",
      "rho_k =  [24.78865392]\n",
      "old sigma = [[1.7328948  1.84222597]]\n",
      "new sigma =  [[2.5993422  2.76333896]]\n",
      "iteration =  9\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-2.58224092 -2.75444331]]\n",
      "trust region best Solution [0.00894067 0.00112796]\n",
      "0.06439088065816323 xbestsolution\n",
      "predicted result =  [0.06928375] actual result =  0.027649479104735253\n",
      "rho_k =  [-7.5091673]\n",
      "old sigma = [[2.5993422  2.76333896]]\n",
      "new sigma =  [[0.64983555 0.69083474]]\n",
      "iteration =  10\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-0.64089488 -0.68970678]]\n",
      "trust region best Solution [-0.00085921 -0.00385783]\n",
      "0.027649479104735253 xbestsolution\n",
      "predicted result =  [0.02791446] actual result =  0.011594854389212816\n",
      "rho_k =  [-60.58801318]\n",
      "old sigma = [[0.64983555 0.69083474]]\n",
      "new sigma =  [[0.16245889 0.17270868]]\n",
      "iteration =  11\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-0.1633181  -0.17656651]]\n",
      "trust region best Solution [-0.00699455 -0.00307809]\n",
      "0.011594854389212816 xbestsolution\n",
      "predicted result =  [0.01361724] actual result =  0.0231688955665601\n",
      "rho_k =  [5.72296558]\n",
      "old sigma = [[0.16245889 0.17270868]]\n",
      "new sigma =  [[0.24368833 0.25906303]]\n",
      "iteration =  12\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-0.24454754 -0.26292086]]\n",
      "trust region best Solution [-0.00333511 -0.00379987]\n",
      "0.011594854389212816 xbestsolution\n",
      "predicted result =  [0.01908048] actual result =  0.014980763427896893\n",
      "rho_k =  [0.45232162]\n",
      "old sigma = [[0.24368833 0.25906303]]\n",
      "new sigma =  [[0.24368833 0.25906303]]\n",
      "iteration =  13\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-0.24454754 -0.26292086]]\n",
      "trust region best Solution [-0.00378794 -0.00376397]\n",
      "0.011594854389212816 xbestsolution\n",
      "predicted result =  [0.01794778] actual result =  0.015863099062411568\n",
      "rho_k =  [0.67185454]\n",
      "old sigma = [[0.24368833 0.25906303]]\n",
      "new sigma =  [[0.24368833 0.25906303]]\n",
      "iteration =  14\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-0.24454754 -0.26292086]]\n",
      "trust region best Solution [-0.00404474 -0.00373841]\n",
      "0.011594854389212816 xbestsolution\n",
      "predicted result =  [0.01749536] actual result =  0.016385980367591646\n",
      "rho_k =  [0.81198511]\n",
      "old sigma = [[0.24368833 0.25906303]]\n",
      "new sigma =  [[0.3655325  0.38859454]]\n",
      "iteration =  15\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-0.36639171 -0.39245237]]\n",
      "trust region best Solution [-0.00419338 -0.0037298 ]\n",
      "0.011594854389212816 xbestsolution\n",
      "predicted result =  [0.01730184] actual result =  0.016711978624237123\n",
      "rho_k =  [0.89664176]\n",
      "old sigma = [[0.3655325  0.38859454]]\n",
      "new sigma =  [[0.54829875 0.58289181]]\n",
      "iteration =  16\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-0.54915796 -0.58674964]]\n",
      "trust region best Solution [-0.0041065  -0.00379524]\n",
      "0.011594854389212816 xbestsolution\n",
      "predicted result =  [0.01732428] actual result =  0.01664817649925654\n",
      "rho_k =  [0.88199423]\n",
      "old sigma = [[0.54829875 0.58289181]]\n",
      "new sigma =  [[0.82244812 0.87433772]]\n",
      "iteration =  17\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-0.82330733 -0.87819555]]\n",
      "trust region best Solution [-0.00430584 -0.00399745]\n",
      "0.011594854389212816 xbestsolution\n",
      "predicted result =  [0.01730688] actual result =  0.017537025338445478\n",
      "rho_k =  [1.04029203]\n",
      "old sigma = [[0.82244812 0.87433772]]\n",
      "new sigma =  [[1.23367218 1.31150657]]\n",
      "iteration =  18\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-1.23453139 -1.3153644 ]]\n",
      "trust region best Solution [-0.00429928 -0.00401551]\n",
      "0.011594854389212816 xbestsolution\n",
      "predicted result =  [0.01733884] actual result =  0.017560619923302045\n",
      "rho_k =  [1.03861093]\n",
      "old sigma = [[1.23367218 1.31150657]]\n",
      "new sigma =  [[1.85050827 1.96725986]]\n",
      "iteration =  19\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-1.85136748 -1.97111769]]\n",
      "trust region best Solution [-0.0049675  -0.00498679]\n",
      "0.011594854389212816 xbestsolution\n",
      "predicted result =  [0.01742333] actual result =  0.021227463045232486\n",
      "rho_k =  [1.65268004]\n",
      "old sigma = [[1.85050827 1.96725986]]\n",
      "new sigma =  [[2.7757624  2.95088979]]\n",
      "iteration =  20\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-2.77662161 -2.95474762]]\n",
      "trust region best Solution [-0.00465728 -0.00643706]\n",
      "0.011594854389212816 xbestsolution\n",
      "predicted result =  [0.01775405] actual result =  0.024152598956210358\n",
      "rho_k =  [2.03886086]\n",
      "old sigma = [[2.7757624  2.95088979]]\n",
      "new sigma =  [[4.1636436  4.42633469]]\n",
      "iteration =  21\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-4.16450281 -4.43019252]]\n",
      "trust region best Solution [-0.00428443 -0.00727937]\n",
      "0.011594854389212816 xbestsolution\n",
      "predicted result =  [0.01837956] actual result =  0.02578955704504482\n",
      "rho_k =  [2.09216246]\n",
      "old sigma = [[4.1636436  4.42633469]]\n",
      "new sigma =  [[6.24546541 6.63950203]]\n",
      "iteration =  22\n",
      "lower bound trust shape:   (1, 2)\n",
      "[[-6.24632462 -6.64335986]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m bounds \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m), (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m)] \u001b[38;5;66;03m#bounds for each dimension (x and y)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m STRLS \u001b[38;5;241m=\u001b[39m STRLS(bounds, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m STRLS\u001b[38;5;241m.\u001b[39minitialTrustRegion(bounds)\n",
      "Cell \u001b[0;32mIn[89], line 170\u001b[0m, in \u001b[0;36mSTRLS.initialTrustRegion\u001b[0;34m(self, localBounds)\u001b[0m\n\u001b[1;32m    167\u001b[0m trustRegionGP \u001b[38;5;241m=\u001b[39m GPTrain(trustRegionFeatures, trustRegionTargets, meanPrior\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    169\u001b[0m trustRegionDE \u001b[38;5;241m=\u001b[39m DifferentialEvolution(trustRegionBounds, trustRegionGP, iteration)\n\u001b[0;32m--> 170\u001b[0m trustBestSolution, trustBestFitness \u001b[38;5;241m=\u001b[39m trustRegionDE\u001b[38;5;241m.\u001b[39moptimize()\n\u001b[1;32m    172\u001b[0m trustBestSolution \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(trustBestSolution, (\u001b[38;5;241m2\u001b[39m,))\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust region best Solution\u001b[39m\u001b[38;5;124m'\u001b[39m, trustBestSolution)\n",
      "Cell \u001b[0;32mIn[87], line 122\u001b[0m, in \u001b[0;36mDifferentialEvolution.optimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation[i]\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# print('break')\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# print(i)\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m mutant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmutate(i)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# print(mutant)\u001b[39;00m\n\u001b[1;32m    124\u001b[0m mutant \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(mutant, (\u001b[38;5;241m2\u001b[39m,))\n",
      "Cell \u001b[0;32mIn[87], line 60\u001b[0m, in \u001b[0;36mDifferentialEvolution.mutate\u001b[0;34m(self, target_idx)\u001b[0m\n\u001b[1;32m     50\u001b[0m r1, r2 , r3\u001b[38;5;241m=\u001b[39m indices[:\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Best individual in current population\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# print(self.population.shape)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#TODO  instead of this list comprehension bollocks just evaluate them all at once\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m#as thats what i think it wants, then find the minimum of the results. \u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m predictedValues \u001b[38;5;241m=\u001b[39m GPEval(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective_function, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation)\n\u001b[1;32m     62\u001b[0m best_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(predictedValues)[:\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     64\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation[best_idx]\n",
      "Cell \u001b[0;32mIn[86], line 63\u001b[0m, in \u001b[0;36mGPEval\u001b[0;34m(model, newFeatures)\u001b[0m\n\u001b[1;32m     60\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), gpytorch\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mfast_pred_var():\n\u001b[0;32m---> 63\u001b[0m     observed_pred \u001b[38;5;241m=\u001b[39m model(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(newFeatures))\n\u001b[1;32m     65\u001b[0m mean_pred \u001b[38;5;241m=\u001b[39m observed_pred\u001b[38;5;241m.\u001b[39mmean\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mean_pred\n",
      "File \u001b[0;32m~/miniconda3/envs/OpenFOAM/lib/python3.11/site-packages/gpytorch/models/exact_gp.py:333\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# Make the prediction\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mcg_tolerance(settings\u001b[38;5;241m.\u001b[39meval_cg_tolerance\u001b[38;5;241m.\u001b[39mvalue()):\n\u001b[1;32m    330\u001b[0m     (\n\u001b[1;32m    331\u001b[0m         predictive_mean,\n\u001b[1;32m    332\u001b[0m         predictive_covar,\n\u001b[0;32m--> 333\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_strategy\u001b[38;5;241m.\u001b[39mexact_prediction(full_mean, full_covar)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Reshape predictive mean to match the appropriate event shape\u001b[39;00m\n\u001b[1;32m    336\u001b[0m predictive_mean \u001b[38;5;241m=\u001b[39m predictive_mean\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mbatch_shape, \u001b[38;5;241m*\u001b[39mtest_shape)\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "File \u001b[0;32m~/miniconda3/envs/OpenFOAM/lib/python3.11/site-packages/gpytorch/models/exact_prediction_strategies.py:281\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_prediction\u001b[0;34m(self, joint_mean, joint_covar)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# For efficiency - we can make things more efficient\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m joint_covar\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mmax_eager_kernel_size\u001b[38;5;241m.\u001b[39mvalue():\n\u001b[0;32m--> 281\u001b[0m     test_covar \u001b[38;5;241m=\u001b[39m joint_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :, :]\u001b[38;5;241m.\u001b[39mto_dense()\n\u001b[1;32m    282\u001b[0m     test_test_covar \u001b[38;5;241m=\u001b[39m test_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :]\n\u001b[1;32m    283\u001b[0m     test_train_covar \u001b[38;5;241m=\u001b[39m test_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train]\n",
      "File \u001b[0;32m~/miniconda3/envs/OpenFOAM/lib/python3.11/site-packages/gpytorch/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m~/miniconda3/envs/OpenFOAM/lib/python3.11/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:410\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.to_dense\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;129m@cached\u001b[39m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dense\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_kernel()\u001b[38;5;241m.\u001b[39mto_dense()\n",
      "File \u001b[0;32m~/miniconda3/envs/OpenFOAM/lib/python3.11/site-packages/gpytorch/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m~/miniconda3/envs/OpenFOAM/lib/python3.11/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:25\u001b[0m, in \u001b[0;36mrecall_grad_state.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(method)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_grad_enabled):\n\u001b[0;32m---> 25\u001b[0m         output \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniconda3/envs/OpenFOAM/lib/python3.11/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:355\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.evaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m     temp_active_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel(\n\u001b[1;32m    356\u001b[0m         x1,\n\u001b[1;32m    357\u001b[0m         x2,\n\u001b[1;32m    358\u001b[0m         diag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    359\u001b[0m         last_dim_is_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_dim_is_batch,\n\u001b[1;32m    360\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams,\n\u001b[1;32m    361\u001b[0m     )\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m temp_active_dims\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# Check the size of the output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/OpenFOAM/lib/python3.11/site-packages/gpytorch/kernels/kernel.py:530\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    527\u001b[0m     res \u001b[38;5;241m=\u001b[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     res \u001b[38;5;241m=\u001b[39m to_linear_operator(\n\u001b[0;32m--> 530\u001b[0m         \u001b[38;5;28msuper\u001b[39m(Kernel, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(x1_, x2_, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    531\u001b[0m     )\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniconda3/envs/OpenFOAM/lib/python3.11/site-packages/gpytorch/module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m~/miniconda3/envs/OpenFOAM/lib/python3.11/site-packages/gpytorch/kernels/scale_kernel.py:109\u001b[0m, in \u001b[0;36mScaleKernel.forward\u001b[0;34m(self, x1, x2, last_dim_is_batch, diag, **params)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x1, x2, last_dim_is_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, diag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m--> 109\u001b[0m     orig_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_kernel\u001b[38;5;241m.\u001b[39mforward(x1, x2, diag\u001b[38;5;241m=\u001b[39mdiag, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    110\u001b[0m     outputscales \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputscale\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m last_dim_is_batch:\n",
      "File \u001b[0;32m~/miniconda3/envs/OpenFOAM/lib/python3.11/site-packages/gpytorch/kernels/rbf_kernel.py:80\u001b[0m, in \u001b[0;36mRBFKernel.forward\u001b[0;34m(self, x1, x2, diag, **params)\u001b[0m\n\u001b[1;32m     78\u001b[0m     x2_ \u001b[38;5;241m=\u001b[39m x2\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlengthscale)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m postprocess_rbf(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovar_dist(x1_, x2_, square_dist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, diag\u001b[38;5;241m=\u001b[39mdiag, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams))\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m RBFCovariance\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     81\u001b[0m     x1,\n\u001b[1;32m     82\u001b[0m     x2,\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlengthscale,\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x1, x2: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovar_dist(x1, x2, square_dist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, diag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams),\n\u001b[1;32m     85\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/OpenFOAM/lib/python3.11/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bounds = [(-5,5), (-5,5)] #bounds for each dimension (x and y)\n",
    "\n",
    "\n",
    "STRLS = STRLS(bounds, 50, 15)\n",
    "\n",
    "STRLS.initialTrustRegion(bounds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TRSPlots/0.png', 'TRSPlots/1.png', 'TRSPlots/2.png', 'TRSPlots/3.png', 'TRSPlots/4.png', 'TRSPlots/5.png', 'TRSPlots/6.png', 'TRSPlots/7.png', 'TRSPlots/8.png', 'TRSPlots/9.png', 'TRSPlots/10.png', 'TRSPlots/11.png', 'TRSPlots/12.png', 'TRSPlots/13.png', 'TRSPlots/14.png', 'TRSPlots/15.png', 'TRSPlots/16.png', 'TRSPlots/17.png', 'TRSPlots/18.png', 'TRSPlots/19.png', 'TRSPlots/20.png', 'TRSPlots/21.png']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "image_files = sorted(glob.glob(\"TRSPlots/*.png\"), key=os.path.getmtime)\n",
    "print(image_files)\n",
    "\n",
    "images = [Image.open(img) for img in image_files]\n",
    "\n",
    "# Step 3: Save images as a GIF\n",
    "if images:\n",
    "    # 'duration' is the time each frame stays on screen (milliseconds)\n",
    "    images[0].save(\n",
    "        \"STRLSResult.gif\",\n",
    "        save_all=True,\n",
    "        append_images=images[1:],  # Include the rest of the images\n",
    "        duration=1000,               # Duration of each frame in milliseconds\n",
    "        loop=0                       # 0 means loop indefinitely\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenFOAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
