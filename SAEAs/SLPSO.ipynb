{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from itertools import product\n",
    "from scipy.stats import qmc  # For Latin Hypercube Sampling\n",
    "import torch\n",
    "import gpytorch\n",
    "import random\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import scienceplots\n",
    "plt.style.available\n",
    "plt.style.use(['science', 'notebook'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialise population\n",
    "evaluate population on function\n",
    "population then ordered according to fitness\n",
    "for each dimension of each particle, a 'demonstrator' is chosen and the long delta equation calculated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Objective function (Ackley function used as an example)\n",
    "# def ackley_function(x, y, a=20, b=0.2, c=2 * np.pi):\n",
    "#     term1 = -a * np.exp(-b * np.sqrt(0.5 * (x**2 + y**2)))\n",
    "#     term2 = -np.exp(0.5 * (np.cos(c * x) + np.cos(c * y)))\n",
    "#     return term1 + term2 + a + np.exp(1)\n",
    "\n",
    "# # Objective function (Ackley function used as an example)\n",
    "# # def ackley_function(x, y, a=20, b=0.2, c=2 * np.pi):\n",
    "# #     z = np.sin(x)+(x*np.cos(0.5*y))\n",
    "# #     return z\n",
    "\n",
    "# def objective_function(vec):\n",
    "#     \"\"\"Objective function wrapper for optimization.\n",
    "#     Args:\n",
    "#         vec (np.ndarray): A vector representing candidate solution (x, y).\n",
    "#     Returns:\n",
    "#         float: Fitness value of the solution.\n",
    "#     \"\"\"\n",
    "#     x, y = vec\n",
    "#     return ackley_function(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SLPSO:\n",
    "#     def __init__(self, bounds, generator, pop_size=50, mutation_factor=0.8, crossover_prob=0.7, max_generations=100, method='random'):\n",
    "#         \"\"\"\n",
    "#         Initialize the Differential Evolution (DE) optimizer.\n",
    "        \n",
    "#         Parameters:\n",
    "#         bounds (list of tuple): List of (min, max) bounds for each dimension.\n",
    "#         pop_size (int): Number of candidate solutions in the population.\n",
    "#         mutation_factor (float): Scaling factor for mutation [0, 2].\n",
    "#         crossover_prob (float): Crossover probability [0, 1].\n",
    "#         max_generations (int): Maximum number of generations to evolve.\n",
    "#         method (str): Population initialization method ('random' or 'lhs').\n",
    "#         \"\"\"\n",
    "#         self.bounds = np.array(bounds)\n",
    "#         self.dimensions = len(bounds)\n",
    "#         self.pop_size = pop_size\n",
    "#         # self.mutation_factor = mutation_factor\n",
    "#         # self.crossover_prob = crossover_prob\n",
    "#         self.max_generations = max_generations\n",
    "\n",
    "#         self.method = method\n",
    "#         self.populationValues = []\n",
    "        \n",
    "#         # Initialize population\n",
    "#         self.population = self.initialize_population()\n",
    "#         self.orderedPopulationIndices = np.empty((pop_size))\n",
    "#         #initialise particle velocities, random value between 0 and \n",
    "#         #10% of function space width (0,1)\n",
    "#         self.generator = generator\n",
    "\n",
    "#         self.particleVelocities = self.generator.uniform(low=0.0, high=1.0, size=((self.pop_size, self.dimensions)))\n",
    "\n",
    "#         self.eta = 2.0\n",
    "#         self.best_solution = None\n",
    "#         self.best_fitness = np.inf\n",
    "    \n",
    "#     def initialize_population(self):\n",
    "#         \"\"\"Initialize population using random sampling or Latin Hypercube Sampling.\"\"\"\n",
    "#         # Latin Hypercube Sampling\n",
    "#         sampler = qmc.LatinHypercube(d=self.dimensions)\n",
    "#         sample = sampler.random(n=self.pop_size)\n",
    "#         population = qmc.scale(sample, self.bounds[:, 0], self.bounds[:, 1])\n",
    "\n",
    "#         #evaluate population on function\n",
    "\n",
    "#         for i in range(0, len(population)):\n",
    "#             self.populationValues = np.append(self.populationValues, objective_function(population[i]))\n",
    "\n",
    "#         # plt.scatter(self.feFeatures[:,0], self.feFeatures[:,1], c = self.feTargets)\n",
    "#         # plt.title('Initial Population')\n",
    "#         # plt.colorbar()\n",
    "#         # plt.show()\n",
    "#         # print(self.populationValues)\n",
    "#         return population\n",
    "    \n",
    "\n",
    "#     def updatePosition(self, pIndex):\n",
    "#         print('updating...')\n",
    "#         for i in range(0, self.dimensions):\n",
    "#             r1, r2, r3 = np.random.random(3)\n",
    "#             meanXd = np.mean(self.population[:,i])\n",
    "\n",
    "#             #different demonstrators (dIndex) chosen for each dimension\n",
    "#             #argsort puts best values at index 0\n",
    "#             #range is (0, len(self.pop_size)-pIndex)\n",
    "#             dIndex = np.random.randint(0, self.pop_size-pIndex)\n",
    "\n",
    "\n",
    "#             #calculate three terms in velocity update equation\n",
    "#             vt1 = r1 * self.particleVelocities[pIndex, i]\n",
    "#             vt2 = r2 * (self.population[dIndex, i] - self.population[pIndex, i])\n",
    "#             vt3 = r3 * self.eta * (meanXd - self.population[pIndex, i])\n",
    "\n",
    "#             deltaX = vt1 + vt2 + vt3\n",
    "\n",
    "#             #update particle position per dimension\n",
    "#             self.population[pIndex, i] += deltaX\n",
    "\n",
    "    \n",
    "#     def optimize(self):\n",
    "#         \"\"\"Run the Differential Evolution optimization.\"\"\"\n",
    "#         x_range = np.linspace(-5, 5, 100)\n",
    "#         y_range = np.linspace(-5, 5, 100)\n",
    "#         X, Y = np.meshgrid(x_range, y_range)\n",
    "#         Z = ackley_function(X, Y)\n",
    "\n",
    "#         for generation in range(self.max_generations):\n",
    "#             self.population = np.clip(self.population, self.bounds[:, 0], self.bounds[:, 1])\n",
    "\n",
    "#             #sort current iteration of values\n",
    "#             self.orderedPopulationIndices = np.argsort(self.populationValues)\n",
    "\n",
    "#             popMax = np.max(self.populationValues)\n",
    "#             popMin = np.min(self.populationValues)\n",
    "#             # print(popMin, popMax)\n",
    "#             epsilon = 1.0e-6\n",
    "\n",
    "#             learningProbability = (self.populationValues - popMin)/(popMax - popMin + epsilon)\n",
    "#             # print(learningProbability)\n",
    "#             #randomly generate probabilities for each particle [0,1]\n",
    "#             particleRGP = self.generator.uniform(low=0, high=1, size=((self.pop_size)))\n",
    "\n",
    "#             #link all particles to a potential 'demonstrator' if probability check passes\n",
    "#             #apart from current best\n",
    "#             for i in range(0, self.pop_size-1):\n",
    "#                 # print('particle probability = ', particleRGP[i], 'learning prob = ', learningProbability[i])\n",
    "#                 if particleRGP[i] < learningProbability[i]:\n",
    "#                     self.updatePosition(i)\n",
    "#             print(generation)\n",
    "#             for i in range(0, self.pop_size):\n",
    "#                 self.populationValues[i] = objective_function(self.population[i])\n",
    "\n",
    "\n",
    "#             plt.contourf(X, Y, Z, levels=50, cmap='viridis')\n",
    "#             plt.scatter(self.population[:, 0], self.population[:, 1], color='red', label='Population', s=10)\n",
    "#             # plt.scatter(best_solution[0], best_solution[1], color='blue', label='Best Solution', s=100)\n",
    "#             plt.legend()\n",
    "#             plt.title(\"DE Optimisation of Ackley Function\")\n",
    "#             plt.colorbar()\n",
    "#             # plt.savefig(f'DEPlots/{timestamp}.png')\n",
    "#             plt.show()\n",
    "        \n",
    "#         return np.min(self.populationValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounds = [(-5,5), (-5,5)] #bounds for each dimension (x and y)\n",
    "# rng = np.random.default_rng()\n",
    "\n",
    "# SLPSO = SLPSO(bounds=bounds, generator=rng)\n",
    "# bestValue = SLPSO.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SLPSO:\n",
    "    def __init__(self, objective_function, bounds, pop_size=50, max_generations=100, eta=2.0, generator=None):\n",
    "        \"\"\"\n",
    "        Initialize the Social Learning Particle Swarm Optimizer (SLPSO).\n",
    "        \n",
    "        Parameters:\n",
    "        objective_function (callable): Function to minimize. Accepts a particle position and returns a fitness value.\n",
    "        bounds (list of tuple): List of (min, max) bounds for each dimension.\n",
    "        pop_size (int): Number of particles in the population.\n",
    "        max_generations (int): Maximum number of generations to evolve.\n",
    "        eta (float): Social learning factor.\n",
    "        generator (np.random.Generator): Random number generator (default_rng() if None).\n",
    "        \"\"\"\n",
    "        self.objective_function = objective_function\n",
    "        self.bounds = np.array(bounds)\n",
    "        self.dimensions = len(bounds)\n",
    "        self.pop_size = pop_size\n",
    "        self.max_generations = max_generations\n",
    "        self.eta = eta\n",
    "        self.generator = generator if generator else np.random.default_rng()\n",
    "        \n",
    "        # Initialize population and velocities\n",
    "        self.population = self._initialize_population()\n",
    "        self.velocities = self._initialize_velocities()\n",
    "        \n",
    "        # Evaluate initial fitness\n",
    "        self.fitness = np.apply_along_axis(self.objective_function, 1, self.population)\n",
    "        \n",
    "        # Initialize global best\n",
    "        self.global_best = self.population[np.argmin(self.fitness)]\n",
    "        self.global_best_fitness = np.min(self.fitness)\n",
    "    \n",
    "    def _initialize_population(self):\n",
    "        \"\"\"Initialize the particle positions uniformly within the bounds.\"\"\"\n",
    "        return self.generator.uniform(low=self.bounds[:, 0], high=self.bounds[:, 1], size=(self.pop_size, self.dimensions))\n",
    "    \n",
    "    def _initialize_velocities(self):\n",
    "        \"\"\"Initialize particle velocities as a small fraction of the bounds range.\"\"\"\n",
    "        velocity_range = (self.bounds[:, 1] - self.bounds[:, 0]) * 0.1\n",
    "        return self.generator.uniform(low=-velocity_range, high=velocity_range, size=(self.pop_size, self.dimensions))\n",
    "    \n",
    "    def _clip_positions(self):\n",
    "        \"\"\"Clip particle positions to stay within bounds.\"\"\"\n",
    "        self.population = np.clip(self.population, self.bounds[:, 0], self.bounds[:, 1])\n",
    "    \n",
    "    def _update_position(self, particle_idx):\n",
    "        \"\"\"Update the position of a single particle using the SLPSO update rule.\"\"\"\n",
    "        for d in range(self.dimensions):\n",
    "            r1, r2, r3 = self.generator.random(3)\n",
    "            mean_d = np.mean(self.population[:, d])\n",
    "            \n",
    "            # Select a random demonstrator (better than the current particle)\n",
    "            demonstrator_indices = np.where(self.fitness < self.fitness[particle_idx])[0]\n",
    "            if len(demonstrator_indices) > 0:\n",
    "                demonstrator_idx = self.generator.choice(demonstrator_indices)\n",
    "            else:\n",
    "                demonstrator_idx = particle_idx  # If no better demonstrators, particle learns from itself\n",
    "            \n",
    "            # Compute velocity components\n",
    "            vt1 = r1 * self.velocities[particle_idx, d]\n",
    "            vt2 = r2 * (self.population[demonstrator_idx, d] - self.population[particle_idx, d])\n",
    "            vt3 = r3 * self.eta * (mean_d - self.population[particle_idx, d])\n",
    "            \n",
    "            # Update velocity and position\n",
    "            self.velocities[particle_idx, d] = vt1 + vt2 + vt3\n",
    "            self.population[particle_idx, d] += self.velocities[particle_idx, d]\n",
    "        \n",
    "        # Ensure the updated position is within bounds\n",
    "        self._clip_positions()\n",
    "    \n",
    "    def optimize(self):\n",
    "        \"\"\"Run the SLPSO optimization.\"\"\"\n",
    "        for generation in range(self.max_generations):\n",
    "            for i in range(self.pop_size):\n",
    "                self._update_position(i)\n",
    "                # Update fitness after position change\n",
    "                self.fitness[i] = self.objective_function(self.population[i])\n",
    "            \n",
    "            # Update global best\n",
    "            current_best_idx = np.argmin(self.fitness)\n",
    "            current_best_fitness = self.fitness[current_best_idx]\n",
    "            if current_best_fitness < self.global_best_fitness:\n",
    "                self.global_best_fitness = current_best_fitness\n",
    "                self.global_best = self.population[current_best_idx]\n",
    "            \n",
    "            # Print progress (optional)\n",
    "            print(f\"Generation {generation + 1}/{self.max_generations}, Best Fitness: {self.global_best_fitness}\")\n",
    "        \n",
    "        return self.global_best, self.global_best_fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1/100, Best Fitness: 2.9172320445407753\n",
      "Generation 2/100, Best Fitness: 2.9172320445407753\n",
      "Generation 3/100, Best Fitness: 2.190439621665853\n",
      "Generation 4/100, Best Fitness: 1.4217003343017862\n",
      "Generation 5/100, Best Fitness: 1.4217003343017862\n",
      "Generation 6/100, Best Fitness: 1.4217003343017862\n",
      "Generation 7/100, Best Fitness: 1.4217003343017862\n",
      "Generation 8/100, Best Fitness: 1.4217003343017862\n",
      "Generation 9/100, Best Fitness: 1.4217003343017862\n",
      "Generation 10/100, Best Fitness: 1.4217003343017862\n",
      "Generation 11/100, Best Fitness: 1.4217003343017862\n",
      "Generation 12/100, Best Fitness: 1.4217003343017862\n",
      "Generation 13/100, Best Fitness: 1.4217003343017862\n",
      "Generation 14/100, Best Fitness: 1.4217003343017862\n",
      "Generation 15/100, Best Fitness: 1.4217003343017862\n",
      "Generation 16/100, Best Fitness: 1.4217003343017862\n",
      "Generation 17/100, Best Fitness: 1.4217003343017862\n",
      "Generation 18/100, Best Fitness: 1.4217003343017862\n",
      "Generation 19/100, Best Fitness: 1.4217003343017862\n",
      "Generation 20/100, Best Fitness: 1.4217003343017862\n",
      "Generation 21/100, Best Fitness: 1.4217003343017862\n",
      "Generation 22/100, Best Fitness: 1.4217003343017862\n",
      "Generation 23/100, Best Fitness: 1.4217003343017862\n",
      "Generation 24/100, Best Fitness: 1.4217003343017862\n",
      "Generation 25/100, Best Fitness: 1.4217003343017862\n",
      "Generation 26/100, Best Fitness: 1.4217003343017862\n",
      "Generation 27/100, Best Fitness: 1.4217003343017862\n",
      "Generation 28/100, Best Fitness: 1.4217003343017862\n",
      "Generation 29/100, Best Fitness: 1.4217003343017862\n",
      "Generation 30/100, Best Fitness: 1.4217003343017862\n",
      "Generation 31/100, Best Fitness: 1.4217003343017862\n",
      "Generation 32/100, Best Fitness: 1.4217003343017862\n",
      "Generation 33/100, Best Fitness: 1.4217003343017862\n",
      "Generation 34/100, Best Fitness: 1.4217003343017862\n",
      "Generation 35/100, Best Fitness: 1.4217003343017862\n",
      "Generation 36/100, Best Fitness: 1.4217003343017862\n",
      "Generation 37/100, Best Fitness: 1.4217003343017862\n",
      "Generation 38/100, Best Fitness: 1.4217003343017862\n",
      "Generation 39/100, Best Fitness: 1.4217003343017862\n",
      "Generation 40/100, Best Fitness: 1.4217003343017862\n",
      "Generation 41/100, Best Fitness: 1.4217003343017862\n",
      "Generation 42/100, Best Fitness: 1.4217003343017862\n",
      "Generation 43/100, Best Fitness: 1.4217003343017862\n",
      "Generation 44/100, Best Fitness: 1.4217003343017862\n",
      "Generation 45/100, Best Fitness: 1.4217003343017862\n",
      "Generation 46/100, Best Fitness: 1.4217003343017862\n",
      "Generation 47/100, Best Fitness: 1.4217003343017862\n",
      "Generation 48/100, Best Fitness: 1.4217003343017862\n",
      "Generation 49/100, Best Fitness: 1.4217003343017862\n",
      "Generation 50/100, Best Fitness: 1.4217003343017862\n",
      "Generation 51/100, Best Fitness: 1.4217003343017862\n",
      "Generation 52/100, Best Fitness: 1.4217003343017862\n",
      "Generation 53/100, Best Fitness: 1.4217003343017862\n",
      "Generation 54/100, Best Fitness: 1.4217003343017862\n",
      "Generation 55/100, Best Fitness: 1.4217003343017862\n",
      "Generation 56/100, Best Fitness: 1.4217003343017862\n",
      "Generation 57/100, Best Fitness: 1.4217003343017862\n",
      "Generation 58/100, Best Fitness: 1.4217003343017862\n",
      "Generation 59/100, Best Fitness: 1.4217003343017862\n",
      "Generation 60/100, Best Fitness: 1.4217003343017862\n",
      "Generation 61/100, Best Fitness: 1.4217003343017862\n",
      "Generation 62/100, Best Fitness: 1.4217003343017862\n",
      "Generation 63/100, Best Fitness: 1.4217003343017862\n",
      "Generation 64/100, Best Fitness: 1.4217003343017862\n",
      "Generation 65/100, Best Fitness: 1.4217003343017862\n",
      "Generation 66/100, Best Fitness: 1.4217003343017862\n",
      "Generation 67/100, Best Fitness: 1.4217003343017862\n",
      "Generation 68/100, Best Fitness: 1.4217003343017862\n",
      "Generation 69/100, Best Fitness: 1.4217003343017862\n",
      "Generation 70/100, Best Fitness: 1.4217003343017862\n",
      "Generation 71/100, Best Fitness: 1.4217003343017862\n",
      "Generation 72/100, Best Fitness: 1.4217003343017862\n",
      "Generation 73/100, Best Fitness: 1.4217003343017862\n",
      "Generation 74/100, Best Fitness: 1.4217003343017862\n",
      "Generation 75/100, Best Fitness: 1.4217003343017862\n",
      "Generation 76/100, Best Fitness: 1.4217003343017862\n",
      "Generation 77/100, Best Fitness: 1.4217003343017862\n",
      "Generation 78/100, Best Fitness: 1.4217003343017862\n",
      "Generation 79/100, Best Fitness: 1.4217003343017862\n",
      "Generation 80/100, Best Fitness: 1.4217003343017862\n",
      "Generation 81/100, Best Fitness: 1.4217003343017862\n",
      "Generation 82/100, Best Fitness: 1.4217003343017862\n",
      "Generation 83/100, Best Fitness: 1.4217003343017862\n",
      "Generation 84/100, Best Fitness: 1.4217003343017862\n",
      "Generation 85/100, Best Fitness: 1.4217003343017862\n",
      "Generation 86/100, Best Fitness: 1.4217003343017862\n",
      "Generation 87/100, Best Fitness: 1.4217003343017862\n",
      "Generation 88/100, Best Fitness: 1.4217003343017862\n",
      "Generation 89/100, Best Fitness: 1.4217003343017862\n",
      "Generation 90/100, Best Fitness: 1.4217003343017862\n",
      "Generation 91/100, Best Fitness: 1.4217003343017862\n",
      "Generation 92/100, Best Fitness: 1.4217003343017862\n",
      "Generation 93/100, Best Fitness: 1.4217003343017862\n",
      "Generation 94/100, Best Fitness: 1.4217003343017862\n",
      "Generation 95/100, Best Fitness: 1.4217003343017862\n",
      "Generation 96/100, Best Fitness: 1.4217003343017862\n",
      "Generation 97/100, Best Fitness: 1.4217003343017862\n",
      "Generation 98/100, Best Fitness: 1.4217003343017862\n",
      "Generation 99/100, Best Fitness: 1.4217003343017862\n",
      "Generation 100/100, Best Fitness: 1.4217003343017862\n",
      "Best solution: [-0.09921112 -0.17833994]\n",
      "Best fitness: 1.4217003343017862\n"
     ]
    }
   ],
   "source": [
    "def ackley_function(x):\n",
    "    \"\"\"Ackley function for optimization (minimum at 0,0,...,0).\"\"\"\n",
    "    a = 20\n",
    "    b = 0.2\n",
    "    c = 2 * np.pi\n",
    "    d = len(x)\n",
    "    sum1 = np.sum(x**2)\n",
    "    sum2 = np.sum(np.cos(c * x))\n",
    "    term1 = -a * np.exp(-b * np.sqrt(sum1 / d))\n",
    "    term2 = -np.exp(sum2 / d)\n",
    "    return term1 + term2 + a + np.exp(1)\n",
    "\n",
    "# Define bounds for the optimization problem\n",
    "bounds = [(-5, 5), (-5, 5)]  # 2D problem\n",
    "\n",
    "# Create the SLPSO optimizer\n",
    "optimizer = SLPSO(\n",
    "    objective_function=ackley_function,\n",
    "    bounds=bounds,\n",
    "    pop_size=30,\n",
    "    max_generations=100\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "best_solution, best_fitness = optimizer.optimize()\n",
    "\n",
    "print(f\"Best solution: {best_solution}\")\n",
    "print(f\"Best fitness: {best_fitness}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenFOAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
